{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ab0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#import zipfile\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "#import cv2\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from PIL import Image\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a135456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#api = KaggleApi()\n",
    "#api.authenticate()\n",
    "\n",
    "#dataset = \"mubashirrahim/wind-power-generation-data-forecasting\"\n",
    "#download_folder = Path(\"../data/external/wind-power-generation-data\")\n",
    "#download_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#api.dataset_download_files(dataset, path=str(download_folder), unzip=True)\n",
    "download_folder = Path(\"../data/external/lfw-dataset\")\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4, data_home=download_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ca72bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[0.9973857 , 0.99607843, 0.9921568 , ..., 0.38169935, 0.38823533,\n",
       "         0.3803922 ],\n",
       "        [0.14771242, 0.19738562, 0.1751634 , ..., 0.45751634, 0.44444445,\n",
       "         0.53594774],\n",
       "        [0.34379086, 0.39477125, 0.49150327, ..., 0.709804  , 0.72156864,\n",
       "         0.7163399 ],\n",
       "        ...,\n",
       "        [0.3633987 , 0.3372549 , 0.30718955, ..., 0.19738562, 0.22091503,\n",
       "         0.19346406],\n",
       "        [0.19346406, 0.24705882, 0.34248367, ..., 0.7346406 , 0.6640523 ,\n",
       "         0.6117647 ],\n",
       "        [0.11633987, 0.10196079, 0.1267974 , ..., 0.13333334, 0.13725491,\n",
       "         0.2535948 ]], shape=(1288, 1850), dtype=float32),\n",
       " 'images': array([[[0.9973857 , 0.99607843, 0.9921568 , ..., 0.29803923,\n",
       "          0.24836601, 0.20653595],\n",
       "         [0.9973857 , 0.9921569 , 0.9908497 , ..., 0.30588236,\n",
       "          0.2535948 , 0.21568628],\n",
       "         [0.96078426, 0.93071896, 0.8679738 , ..., 0.2875817 ,\n",
       "          0.24183007, 0.21568628],\n",
       "         ...,\n",
       "         [0.34509805, 0.26143792, 0.17385621, ..., 0.4248366 ,\n",
       "          0.40261438, 0.39084968],\n",
       "         [0.30980393, 0.23398693, 0.17124183, ..., 0.39869282,\n",
       "          0.4013072 , 0.3764706 ],\n",
       "         [0.28366014, 0.2248366 , 0.18039216, ..., 0.38169935,\n",
       "          0.38823533, 0.3803922 ]],\n",
       " \n",
       "        [[0.14771242, 0.19738562, 0.1751634 , ..., 0.24183007,\n",
       "          0.2       , 0.14509805],\n",
       "         [0.18039216, 0.24836601, 0.24575163, ..., 0.21437909,\n",
       "          0.21960784, 0.1751634 ],\n",
       "         [0.21045752, 0.303268  , 0.33594772, ..., 0.2653595 ,\n",
       "          0.18431373, 0.16993465],\n",
       "         ...,\n",
       "         [0.2875817 , 0.29803923, 0.29673204, ..., 0.503268  ,\n",
       "          0.46797386, 0.4535948 ],\n",
       "         [0.29411766, 0.29803923, 0.303268  , ..., 0.4928105 ,\n",
       "          0.4496732 , 0.45359477],\n",
       "         [0.30457518, 0.29673204, 0.29673204, ..., 0.45751634,\n",
       "          0.44444445, 0.53594774]],\n",
       " \n",
       "        [[0.34379086, 0.39477125, 0.49150327, ..., 0.5803922 ,\n",
       "          0.58954257, 0.58300656],\n",
       "         [0.38169935, 0.5071896 , 0.57124186, ..., 0.6261439 ,\n",
       "          0.5908497 , 0.5751634 ],\n",
       "         [0.48366013, 0.5686275 , 0.579085  , ..., 0.64183015,\n",
       "          0.59738564, 0.5751634 ],\n",
       "         ...,\n",
       "         [0.29673204, 0.2875817 , 0.28496733, ..., 0.46013072,\n",
       "          0.6732027 , 0.70326805],\n",
       "         [0.28627452, 0.26666668, 0.27058825, ..., 0.5908497 ,\n",
       "          0.7267974 , 0.7098039 ],\n",
       "         [0.3150327 , 0.25490198, 0.26013073, ..., 0.709804  ,\n",
       "          0.72156864, 0.7163399 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.3633987 , 0.3372549 , 0.30718955, ..., 0.1633987 ,\n",
       "          0.1633987 , 0.18562092],\n",
       "         [0.35947713, 0.3124183 , 0.32026145, ..., 0.16993465,\n",
       "          0.16209151, 0.17124183],\n",
       "         [0.30457518, 0.26666668, 0.38039216, ..., 0.18562092,\n",
       "          0.17254902, 0.16993465],\n",
       "         ...,\n",
       "         [0.38169935, 0.36601308, 0.35947713, ..., 0.2901961 ,\n",
       "          0.34509805, 0.4       ],\n",
       "         [0.36078432, 0.35816994, 0.37254903, ..., 0.20261438,\n",
       "          0.25490198, 0.27450982],\n",
       "         [0.32156864, 0.3281046 , 0.34117648, ..., 0.19738562,\n",
       "          0.22091503, 0.19346406]],\n",
       " \n",
       "        [[0.19346406, 0.24705882, 0.34248367, ..., 0.5882353 ,\n",
       "          0.5947712 , 0.5647059 ],\n",
       "         [0.22875817, 0.32287583, 0.39084968, ..., 0.58300656,\n",
       "          0.56078434, 0.55947715],\n",
       "         [0.23006536, 0.351634  , 0.37124184, ..., 0.5882353 ,\n",
       "          0.53464055, 0.53464055],\n",
       "         ...,\n",
       "         [0.23660131, 0.23921569, 0.24313726, ..., 0.5542484 ,\n",
       "          0.63137263, 0.6104575 ],\n",
       "         [0.24052288, 0.24183007, 0.24575163, ..., 0.71111107,\n",
       "          0.6535948 , 0.6169935 ],\n",
       "         [0.24183007, 0.24052288, 0.24444444, ..., 0.7346406 ,\n",
       "          0.6640523 , 0.6117647 ]],\n",
       " \n",
       "        [[0.11633987, 0.10196079, 0.1267974 , ..., 0.34248367,\n",
       "          0.20130719, 0.17908497],\n",
       "         [0.12156863, 0.12418301, 0.14379086, ..., 0.41045752,\n",
       "          0.20522876, 0.15816994],\n",
       "         [0.13071896, 0.13202615, 0.14901961, ..., 0.4888889 ,\n",
       "          0.26928106, 0.19477125],\n",
       "         ...,\n",
       "         [0.18169935, 0.17254902, 0.17254902, ..., 0.09281046,\n",
       "          0.07058824, 0.13986929],\n",
       "         [0.16470589, 0.1633987 , 0.1764706 , ..., 0.0875817 ,\n",
       "          0.10326798, 0.1764706 ],\n",
       "         [0.17908497, 0.19477125, 0.20392157, ..., 0.13333334,\n",
       "          0.13725491, 0.2535948 ]]], shape=(1288, 50, 37), dtype=float32),\n",
       " 'target': array([5, 6, 3, ..., 5, 3, 5], shape=(1288,)),\n",
       " 'target_names': array(['Ariel Sharon', 'Colin Powell', 'Donald Rumsfeld', 'George W Bush',\n",
       "        'Gerhard Schroeder', 'Hugo Chavez', 'Tony Blair'], dtype='<U17'),\n",
       " 'DESCR': \".. _labeled_faces_in_the_wild_dataset:\\n\\nThe Labeled Faces in the Wild face recognition dataset\\n------------------------------------------------------\\n\\nThis dataset is a collection of JPEG pictures of famous people collected\\nover the internet, and the details are available on the Kaggle website:\\n\\nhttps://www.kaggle.com/datasets/jessicali9530/lfw-dataset\\n\\nEach picture is centered on a single face. The typical task is called\\nFace Verification: given a pair of two pictures, a binary classifier\\nmust predict whether the two images are from the same person.\\n\\nAn alternative task, Face Recognition or Face Identification is:\\ngiven the picture of the face of an unknown person, identify the name\\nof the person by referring to a gallery of previously seen pictures of\\nidentified persons.\\n\\nBoth Face Verification and Face Recognition are tasks that are typically\\nperformed on the output of a model trained to perform Face Detection. The\\nmost popular model for Face Detection is called Viola-Jones and is\\nimplemented in the OpenCV library. The LFW faces were extracted by this\\nface detector from various online websites.\\n\\n**Data Set Characteristics:**\\n\\n=================   =======================\\nClasses                                5749\\nSamples total                         13233\\nDimensionality                         5828\\nFeatures            real, between 0 and 255\\n=================   =======================\\n\\n.. dropdown:: Usage\\n\\n  ``scikit-learn`` provides two loaders that will automatically download,\\n  cache, parse the metadata files, decode the jpeg and convert the\\n  interesting slices into memmapped numpy arrays. This dataset size is more\\n  than 200 MB. The first load typically takes more than a couple of minutes\\n  to fully decode the relevant part of the JPEG files into numpy arrays. If\\n  the dataset has  been loaded once, the following times the loading times\\n  less than 200ms by using a memmapped version memoized on the disk in the\\n  ``~/scikit_learn_data/lfw_home/`` folder using ``joblib``.\\n\\n  The first loader is used for the Face Identification task: a multi-class\\n  classification task (hence supervised learning)::\\n\\n    >>> from sklearn.datasets import fetch_lfw_people\\n    >>> lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\\n\\n    >>> for name in lfw_people.target_names:\\n    ...     print(name)\\n    ...\\n    Ariel Sharon\\n    Colin Powell\\n    Donald Rumsfeld\\n    George W Bush\\n    Gerhard Schroeder\\n    Hugo Chavez\\n    Tony Blair\\n\\n  The default slice is a rectangular shape around the face, removing\\n  most of the background::\\n\\n    >>> lfw_people.data.dtype\\n    dtype('float32')\\n\\n    >>> lfw_people.data.shape\\n    (1288, 1850)\\n\\n    >>> lfw_people.images.shape\\n    (1288, 50, 37)\\n\\n  Each of the ``1140`` faces is assigned to a single person id in the ``target``\\n  array::\\n\\n    >>> lfw_people.target.shape\\n    (1288,)\\n\\n    >>> list(lfw_people.target[:10])\\n    [5, 6, 3, 1, 0, 1, 3, 4, 3, 0]\\n\\n  The second loader is typically used for the face verification task: each sample\\n  is a pair of two picture belonging or not to the same person::\\n\\n    >>> from sklearn.datasets import fetch_lfw_pairs\\n    >>> lfw_pairs_train = fetch_lfw_pairs(subset='train')\\n\\n    >>> list(lfw_pairs_train.target_names)\\n    ['Different persons', 'Same person']\\n\\n    >>> lfw_pairs_train.pairs.shape\\n    (2200, 2, 62, 47)\\n\\n    >>> lfw_pairs_train.data.shape\\n    (2200, 5828)\\n\\n    >>> lfw_pairs_train.target.shape\\n    (2200,)\\n\\n  Both for the :func:`sklearn.datasets.fetch_lfw_people` and\\n  :func:`sklearn.datasets.fetch_lfw_pairs` function it is\\n  possible to get an additional dimension with the RGB color channels by\\n  passing ``color=True``, in that case the shape will be\\n  ``(2200, 2, 62, 47, 3)``.\\n\\n  The :func:`sklearn.datasets.fetch_lfw_pairs` datasets is subdivided into\\n  3 subsets: the development ``train`` set, the development ``test`` set and\\n  an evaluation ``10_folds`` set meant to compute performance metrics using a\\n  10-folds cross validation scheme.\\n\\n.. rubric:: References\\n\\n* `Labeled Faces in the Wild: A Database for Studying Face Recognition\\n  in Unconstrained Environments.\\n  <https://people.cs.umass.edu/~elm/papers/lfw.pdf>`_\\n  Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.\\n  University of Massachusetts, Amherst, Technical Report 07-49, October, 2007.\\n\\n\\n.. rubric:: Examples\\n\\n* :ref:`sphx_glr_auto_examples_applications_plot_face_recognition.py`\\n\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfw_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c947c5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAGfCAYAAAAu+AtQAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMuBJREFUeJzt3Q2MHeV5L/BnZs732bPn7Hq9uzbeBROoDSE2ikvAobdNjIsVRRHUvlepVKluihqFAiqYe9tYaohatTINuoGQGKgoBVVK6spVnZTcW1pksGlubRKb0PDpQgL2mvXuer/Onj1f83n1DvWWZc/zzHps42O//590Qrzvzpw5M3OenT3z3+c1giAICABAQ+b53gAAgPMFBRAAtIUCCADaQgEEAG2hAAKAtlAAAUBbKIAAoC0UQADQFgogAGgLBRAAtJU4VyveuXMnPfDAAzQyMkJr166lb3/72/SpT30qcjnf92l4eJgKhQIZhnGuNg8ALmLqL3wrlQotX76cTFO4zgvOgV27dgWpVCr467/+6+C1114Lfu/3fi8olUrB6Oho5LJDQ0Pqb5PxwAMPPIIzfah6IjHU/5zt6nv99dfTddddR9/5znfmruoGBgborrvuoq9+9avisuVymUqlEt247n9SwkovGLdLKXF5q+mzY15K/o1/5NP8BbG7zGbHupfMiutd1T3Kjq3Oj4jLlhI1dqzPKrNjRasurrfb5Me7TE9c1op5ZV715VNtxk9SXI7waU4jkNc76y88z06pCmNlPyeud8LpYMcmnby47JTDrztrObE/0zpp88/7xlifuGxziH89+SH+mbPj/HtSkc6mVFk+F9OTzZZfd70m/eil/03T09NULBY/ul+Bbdumw4cP0/bt2+e+pi5BN27cSAcOHFjw/c1mM3ycoi5bww2z0pRIZBZ8v5+MKIAev7ONpHx6mBl+d5hZflkrx5+QSjLPb3OmQ35zZhP8NuUSFjuWt+TX2iH8WlAwg3NSAM2IAuj78T+StoW3vhXI6/V9fj8GwpjtyW+fjMMf27QwpqQc/pxJWfz+N8MLH16yya/XyvHFPlx3JsMvmxb2fyqiAAqbnEjKBTCRkM/FqI/RzvpNkPHxcfI8j/r65v80Uf9Wnwd+2I4dO8IKfeqhrhQBALS4C6yuFNWvvaceQ0ND53uTAEATZ/1X4J6eHrIsi0ZH53/upf7d39+/4PvT6XT4AAC44AtgKpWidevW0d69e+nWW2+duwmi/n3nnXcuej1uPqF+wV/w9UY3/5lMKODHZ1bKF7zeAH9jIJvjb4IMdE6J612WmWHHOqyGuGxvgl+2ZPE3SEqmvN6CcKMjGfG5iSV8bJ00+H1sRtxcyRjyZ6mSSsBv07T8ERRlhJsKJbN2Tra3GchvPU/6TJP4F+QI579iCh+4XdkzLi5bKb7/+Xwrv+js5Z/zZflz+473+PPCEz5bVNxc689SXVc+185pDnDbtm20detW+uVf/uUw+/fQQw9RtVqlL33pS+fi6QAAYjknBfCLX/winTx5ku67777wxse1115LzzzzzIIbIwAAF+Vfgqhfd0/nV14AAO3uAgMAnC8ogACgLRRAANAWCiAAaOuc3QQ5U27eIkouzDQ1uqJyQfxY/VI5t5Ww+IyUFI1LWRH5NpN/3rzZ+o+5TykITQtSxD+vFfU3ocJYzpD/TjVt8KeNJeQAs4EcyKsHfNbSiVjWEbJxSyL2sXRGOeKf6stqQiOFMaNTXDZn2rEygt4Z/D11I+Jvmy8vTLBjfVfxGcGDicvF9SaqfE6w8J78njWYXi7c1z8MV4AAoC0UQADQFgogAGgLBRAAtIUCCADaQgEEAG21bQymUbLISlmnFXNR7KIQZUnKUYpAaKkk3VWvuXK7n5rHj9sRbZEqfpYdKyTklldx29rnTPn1xH/OiJ+3wj52ImI9GeH1ZIz4c5VIcaLIqJHhxYq5RJHWe8Lm579QXCEmk7FceVlhaoHuFN82bMWySXG9JweXsWOdxyKmZ6i2jskE7uJaleEKEAC0hQIIANpCAQQAbaEAAoC2UAABQFsogACgLRRAANBW2+YA1ex+rWb4S5XlXFCzix8zEhHzIwpTBkoZwaoj5+aqHt8WqebLy9rCNIeNgG9blRLaQykVn8+SpQ2+BVeUjNAqy4toUdQI+G1qLLK9UZyf8tKeagj73yZ5CkpPaKWVFlqkRS1bEKY8bSTkVmbDRjF2O6zReoEd68vy7bD68/zUrsrxXn5KzWZJ3qbUeOv8oektblpMXAECgLZQAAFAWyiAAKAtFEAA0BYKIABoCwUQALTVtjGYzKRPiRbtq+pL5JotdT4KXHlZM+XFi8HYcpRl2uZbWo0n+WiBkjH4uERKaItUM/jojeIRH1tIGvFbNdWEmeqiTAutmpoRbcPiRkqUjLAfJ4R2ZCddeWa3hp+MPRugJYRzpPjThJOP3Q7L8eVYjy+8B07UOmOvl/J8G65qv3weZ0dbj7suZoUDABChAAKAtlAAAUBbKIAAoC0UQADQFgogAGirbWMw6bJDicTC2+ezyzPicqYtdHRxIuq9EIOxLD6W4Hhm7BjMZEqOLUizh2WEjiIli5+lK4o0w5qSjIiVcLyIWdScc/Tz2BE6uijVgI8xTXodseIo7z8v//ayDLlbjyfsizGbj5xM2hExGGFf+ELMRZlt8pGUss+/L203osyY/HnhyCkxcoqtj4HroBsMAIAIBRAAtIUCCADaQgEEAG2hAAKAtlAAAUBbKIAAoK22zQEabkBGi9yYH7HFhitkmaSxCKbJ57aySb6dj1JK8bOsJYRWTFFZP1NomeQF8s+2ipDbmvblGcsKQoZNejW1iJyZNANbZJbPl9smSXzhOkBarxfxepwzeD2zHn98TjT5md0mmzlxvTNNfr0J4RxXXCHvWmvwWUqnKb9pgya/LyJOY7I7Wi/rOhEtuP4TrgABQFsogACgLRRAANAWCiAAaAsFEAC0hQIIANpq3xiMH4SPDzPlxAlJXYbMulzv/Q4+1uA4/K5K5uXWU6axuBmqWi/rx5oVLiO00Ypy0uPbdyme2WDHfKFVljTDmpISQjTJiLjQmbT/klpeSXGVqOjNlJuPNWOcMu3wcZaTjY5YMRelKbWmSrixo2CeK8ROfDkuZDT592XEYSduNwaLfMvhChAAtIUCCADaQgEEAG2hAAKAtlAAAUBbKIAAoC0UQADQVtvmAP2kSX5iYX02nYiAj9CiyLIj2hc1+N3hJaRpMRfXeqeVJcmqOJ4x5NZUcZcrCFk+L2LaS0vINTb9+PuiIGQXcxGBMKmR00REXk/K89nC1JZRLa2k8bon5wCl8Vmb397pmpy1zKXt2O29Gja/Tb4w5WzQkPeT1eSfNyKSSm669bJexNSup+AKEAC0hQIIANpCAQQAbaEAAoC2UAABQFsogACgrdOOwbzwwgv0wAMP0OHDh+nEiRO0Z88euvXWW+fGgyCgr3/96/T444/T9PQ03XjjjfToo4/SlVdeeVrPYzVcslq05zEdOdJgCekPLyJRYgjtstw0fyvf9SPabAnxgmbENHdlLxerBVRUDCYjxEqciKm4ouISnE6jGXub5PnK1Cx3fESjFhmD4Wc0s4RnjmrRlTb49lJTgTx7m9RWzJLaUgkztykzVb5dlhFxWKWZ1swkv03+rHyOWzX+iRMRXc649nhBRNu8ueXpNFWrVVq7di3t3Lmz5fg3vvENevjhh+mxxx6jF198kfL5PG3atIkaDT53BgBwQVwBfu5znwsfrairv4ceeoj++I//mG655Zbwa3/zN39DfX199P3vf59+8zd/88y3GACgHT8DfOedd2hkZIQ2btw497VisUjXX389HThwoOUyzWaTZmZm5j0AAC64AqiKn6Ku+D5I/fvU2Ift2LEjLJKnHgMDA2dzkwAA2vcu8Pbt26lcLs89hoaGzvcmAYAmzmoB7O/vD/87Ojo67+vq36fGPiydTlNnZ+e8BwDABdcNZuXKlWGh27t3L1177bXh19Rneupu8O233356G3ZyhhLmwthEeoXcHsIuWbG6TijCXX4yhW4wRsSsbw2P382jzc7YHUW6EtXYM5ZJEY6o2IgUsbGJ314/Il4zE6Rjb9N7Thc75kX8nB9z+GNQ8fjYyFCNf07laIUfHy/zM7spgTCTWj7Hx4kyKTn+VJmNaK8Sc1Y4Q4rmZCKmdjPN2DGYj7wAzs7O0ttvvz3vxsfLL79M3d3dNDg4SHfffTf92Z/9WZj7UwXxa1/7Gi1fvnxeVhAAoB2cdgE8dOgQffazn53797Zt28L/bt26lZ566in6wz/8wzAr+OUvfzkMQv/Kr/wKPfPMM5TJyPOVAgC0fQH8zGc+E+b9OIZh0J/+6Z+GDwCAdnbe7wIDAJwvKIAAoC0UQADQFgogAGirbWeF46Qn5T43jRJf051cRL8fIa7k1fhdNWnlxdW6wqxx1Ww6dlskOcvHt3iKnhVO/rmYMfiZxSY9Pt/2bqNHXG/VTcdqKaa8Od3Ljo1NyllLMcPmCi2g3pOTDckZoaWVuCSRW+BvNE738K2/MkW55ZiV8GK9VsVz+fPCsPjtNSNygG6Of28JEwWGMuXW63adiOzhqfUv6rsAAC5CKIAAoC0UQADQFgogAGgLBRAAtIUCCADaatsYjLekQIa1MGZg1eUYTGAJM3zJCQHqOCq0ckoIs8Ll+ViCMpXnZwCbtLrFZd/q4uMdxRLfK6ivUBHXe0muTHElTD5i8PbMUnZseKoorlf4E3NqluXISfYofwzyES9V6mZmNflBPyLL4gkJJyNimjtDaIdFwgx4zZq8UUFaeOKk3NZNmprPyvHvy0QyIgazlH9j1ifl9l2F91pvs+lEvJZT37eo7wIAuAihAAKAtlAAAUBbKIAAoC0UQADQFgogAGgLBRAAtNW2OcAwW5dYmHdKTsjz5Jk2n7krvivnkTITwpSCi4sVteSlhTZCEeut9/C5xuoyPhv3dr88ZeOJK6fZsWWdM+KypXSdHZuq8bmt5gh/bJTUFL+fiuNyO6z8CB9Sy47JPZW8DJ+dm/4Yn7mb/oScSU118S3H7Ck515g7yr8188f5feFl5Ryg08GPN5fI74+gwL/edJp/76SEFlzh81r8a230yO3iaj2tl/XsxZU2XAECgLZQAAFAWyiAAKAtFEAA0BYKIABoCwUQALTVtjEY1fbKSiy87R4k5dv8qWoQe0Y5w+GjFHYXH0dxM3JEIzPBP29qrCovy7T7UYr/wUc07JIcHxiZ4WMynZvGxGVv7fkpPyhM/PZ47r+J6534xxXsWOG4HKVIVPlxQ+qzFbZQizdmzcrXD7YpHANhFjWlsZQ/F02Hf94En7wJBcImexn59ThZM1bUJZMS4mURM/7VpfZdanwpE4NpRswA+Z9wBQgA2kIBBABtoQACgLZQAAFAWyiAAKAtFEAA0FbbxmAM1ycjWHhr3U/Jm2y6fLwgUZNvx1cu47uVTF8pdHSR0zWUK/DLdqTkn0HpUb77jVnhMw/ZCXlWuN40P9tc7SY+8qNcnuJjMgPC1HvD/a+K631s2SXsWH5EjjWIEQ5DXtYQEjadR/mDm6xEdV7hY0pBxDsvVebP44YQNZodkOM1pnCu+qn4LY8aNv9aCxl5OsasEJOpCLPNhc/b2/oY+A3MCgcAIEIBBABtoQACgLZQAAFAWyiAAKAtFEAA0BYKIABoq81zgAtb4bhL+LyR4iX5zJefMGMvu+Q1PiyWOy7PVEem0O6nX54dzOvkM3l+hj98iZlG7PZR0w1+Zjel4vPbfFTot+RIvaXUPr6WzxeeyC0Vl+0QZlHLTMqZsGaJPz6ln/M5tPyYnFEbW86fq06nvE2+xW9Ts4tf1u2Wt8nM8uOGKW9TOmbLK8uUW1oVE/yytU75/V6ptj7ufsRMdKfgChAAtIUCCADaQgEEAG2hAAKAtlAAAUBbKIAAoK22jcEEphk+PszJy1EKu5OPD5iuPFNa4Tjftic1OsuO+Tm5fZTR4G/zJ2fk2/zTl/ORE0NIFySacpTl5LX8flqVqYvLvtXspzjea5bE8euWHmPH1l72/8Rln59azY79+Oil4rLZrM2ODV3RGbul1apfOsqOdSTlFlHvzRbZsUvSfMSp4crnk+Pz1zyWIcdgktbioiUflpBOVPX+If5c9Dz5Gs3wjdP6+ofhChAAtIUCCADaQgEEAG2hAAKAtlAAAUBbKIAAoC0UQADQVtvmAL1CkozEwnxdsyjX7HoPn/9xM3KGUIgj0fTlS9ix2vLFZY5aqQ/IU3WuuoLPxlVsPtdou/KhvSRlx85tlb1crJZXw3U+26asyE2zYwPJCXHZ/770EDvWl54Rl51x+cxkvZfP1XUm5ZZjXiCci758Lha7+HX3pPlMqivk/JSOBJ8/TErzg6qMoc/vi3dr/Pvj52V+TAmE/WRGtOgybCYH6CAHCAAgQgEEAG2hAAKAtlAAAUBbKIAAoC0UQADQ1mnFYHbs2EH/8A//QG+++SZls1n69Kc/TX/xF39Bq1atmvueRqNB9957L+3atYuazSZt2rSJHnnkEerr6zutDVMzuLWaxc3pkG9vSy2KPHkCNipfxkcTGj3CTFy9fKRE6ejiZ427qsRHP5SMJcdkOLWI1kaVJt/Cq1Not6RMunl2rCq0HKu5ctuwuifELBx5VrjLkifZsa6kPGvfrMdvsy9ENIZrcqzHFOJEOWEmtKioS860Y1/S9CXL7FjJkvfTSZdvDXYy0cGOuZ4c+Wk4/JvWdeVlDdc4ra+f0RXg/v376Y477qCDBw/Ss88+S47j0M0330zVanXue+655x56+umnaffu3eH3Dw8P0+bNm0/naQAA2u8K8Jlnnpn376eeeop6e3vp8OHD9Ku/+qtULpfpiSeeoO9973u0YcOG8HuefPJJuuqqq8KiecMNN5zdrQcAOF+fAaqCp3R3d4f/VYVQXRVu3Lhx7ntWr15Ng4ODdODAgZbrUL8mz8zMzHsAALR1AfR9n+6++2668cYb6Zprrgm/NjIyQqlUikql+a3P1ed/aoz7XLFYLM49BgYG4m4SAMBHUwDVZ4GvvvpqeLPjTGzfvj28kjz1GBoaOqP1AQCc02YId955J/3whz+kF154gVasWDH39f7+frJtm6anp+ddBY6OjoZjraTT6fABANDWBTAIArrrrrtoz549tG/fPlq5cuW88XXr1lEymaS9e/fSli1bwq8dOXKEjh07RuvXrz+tDVPpg1YJBIdPYISaS/joQRDRWcKqx7sgTpyUZ+KqT/HxgV8MyLf5r+gdZ8c6U3xcxYnoNhIEciQlblxl0s6dk/WOOwVx2dXpYXbssx2vi8tOZPkIR8XPxuqOooy7hdjLWkKEpubxx+5jmTFxvUsT/GfsI648a98Jm4/9TDT5N6Yvv+2o2eD3hVOT91O61jru4jWMs18A1a+96g7vD37wAyoUCnOf66nP7lQuUP33tttuo23btoU3Rjo7O8OCqYof7gADQLs5rQL46KOPhv/9zGc+M+/rKuryO7/zO+H/f/DBB8k0zfAK8INBaACAC/5X4CiZTIZ27twZPgAA2hn+FhgAtIUCCADaQgEEAG2hAAKAttp3Vri0RUayRZYtIt7jZ/j8VLq7Li5rC3mkoM7n6oysPJtWIsmPDyyR22Fd3sHnAE2h5VW5yefXomYP68tUxGV7U/x4xY3oOSZuE7+PcxY/m5lS8/kw/aqIGeWuFmZ3qwT8+TTty2+f15vL2LEJj88eKmWXz1MWE/VY+cGo/XTCLsWePa8hZDijZih0qvyy1pScA0wxsUZPPl3m4AoQALSFAggA2kIBBABtoQACgLZQAAFAWyiAAKCtto3BOHmTguTC+pyUExpkOHxOptQhx2Dy3fyMWe9N8q2AkkLMRenv5Df6k91yA9gVqSl27EitdY9F5d3x96cpiLPNpYhZ1HqTfEul8SQf7/h5uUdc73gtH2uWNGUgOcmOycEQIo/4OJEn/Pl7xpCP++UpvjXVUl+e+mHE4iMpVSHK4gXyNc1Rhz8Gw015lruTDf7YTjX4iIxty2XGrPDjQuInxCWRfPnQ/NdzL+7bAAAuPiiAAKAtFEAA0BYKIABoCwUQALSFAggA2kIBBABttW0O0E8Z5KUWZvrSZTnVlZjla7ontIBSrug8yY59ooufdtFvNX/nB/RzPXtUvi0i2JgxbHbs3Sqf9XNG5XZYRn8tVpstZVBoLzWW5KcAdSL2v2Skwa9X+W7tenbsoNBSTPkfXT9mx5aYfF8lL+K4izlBk2/BpTSsKjtmCclGO5CnQ5Wm47Qj2ntVHL7V2WyDzybas/IUrJa7uCksW/GYp11kDBBXgACgLxRAANAWCiAAaAsFEAC0hQIIANpCAQQAbbVtDKbWa5CVXnh7PMsnVUKJWf6W+sSEPBPXex2lWLOzpU1XXG/NT8WeiWvU5uMfbxzn22EFqSD2DHhHa3IrrekcP2PZlMOPVeryjHGXFPl2ZMuz/Jgy3uSP7T++9Qlx2edyV7Jj/+uXno3V7krxI1pTSZwgESvqIs36Fm6TMK1iXZjZTZm1+fO4WuOf15qWy4yUFvLkBA1RuvV57lvy+X8KrgABQFsogACgLRRAANAWCiAAaAsFEAC0hQIIANpq2xiMmyUKWtxZtwty5wjL4ceCmvxyT1QKsTq+ZKQnjeBGdO945ReXsGPJET4jEJUCSB7j98WL3kpx2UPvXsqO+VP8Nhm2fOx+0c/HMOquHNFIJ/goUuDLz1t+cwk7tv3kFnbs8594RVzv8vQ0O1ZMyDPvjTl8/MkUZrGzDLlb0vF6Fzs2WuPPf2V6lo84eWX+uKca8v6X0kIRbw8KmBM9SCAGAwAgQgEEAG2hAAKAtlAAAUBbKIAAoC0UQADQFgogAGirbXOAKiZltWiTYxfl5Sxhsq3UuBwqmsrxLZUqs/wsax15eYYvy+QzSeNDcjus7p9a4sx5nM535RZd2RE+h9b4d3lGOT/Jb5Np8zm0ZEXepiDB/zy2i0vFZU8O8qeyf4Ocuev/xCg7Nv4i33Ls/1avFdc7uIpfb0eKn21uMTPzcRJSbymVda3y+cLJmby4rF3mW14lKvw5YUTM+hYk+dcaMfHeGcMVIABoCwUQALSFAggA2kIBBABtoQACgLZQAAFAW20bg0mXA7JazGxW4Tsx/Sf+vnl2LOp2PH+b383x8Y6pmtyqiRz+50zpVfkQJBp8RKAiJENSFblFl/nuCXYs/578eoKCEJfw+f0U5OQZy2av4DNOjaL8s9oRJvzrKc2Ky65ZMsyO/esafia7zHNyhOlEeRk/eGVVXLZTiFY1XSEa5cv7qSnMBujOysfdrAlRFyl9EzPSEz6nnJwig2l1ZkS04Jpbf5yNAgC4GKAAAoC2UAABQFsogACgLRRAANAWCiAAaAsFEAC01bY5wEQ9IMtbmB9KVczYU+xlpvzYPw/sIp+B8rLyNiUrfCapcFwOOk1/TGjzlObzVTODfH5N6fQH2bHkWEVc1ijz40EX326pejk/ppz4tJDh/FhZXHZpnm951ZuTX48n9Fz6tRU/Z8f+z7WfENfbu4/P1VUrQnBRteFaKRy/tBC6c+Vz0ajz41YzYlkhzmdJubuISF4gtIuLmOWTTKf1ygPm6wuWX9R3AQBchFAAAUBbKIAAoC0UQADQFgogAGgLBRAAtHVaMZhHH300fLz77rvhvz/+8Y/TfffdR5/73OfCfzcaDbr33ntp165d1Gw2adOmTfTII49QX1/f6W+Zuovd4k52ekJurdPo4W9/m3KHKCoc5+MF9Rr/syKI2IuJmjDrlSXfrm928cu6BaFV1mBUpIFvTWX1p+Rl/SXsWLLK5xbKl8k7yu/lW0AlW00R+AHdGb69VMaSD3zV5feF7fPxp0sHxsX1vncN3w5ryc/kfEeizu+rWr/QDiuiM5tlU+wZ2Axhk6X3lpuV37NBQhj35I3ymWXFdca9AlyxYgXdf//9dPjwYTp06BBt2LCBbrnlFnrttdfC8XvuuYeefvpp2r17N+3fv5+Gh4dp8+bNp/MUAADteQX4hS98Yd6///zP/zy8Ijx48GBYHJ944gn63ve+FxZG5cknn6SrrroqHL/hhhvO7pYDAJyvzwA9zwt/1a1Wq7R+/frwqtBxHNq4cePc96xevZoGBwfpwIED7HrUr8ozMzPzHgAAbVkAX3nlFero6KB0Ok1f+cpXaM+ePXT11VfTyMgIpVIpKpXmtwlXn/+pMc6OHTuoWCzOPQYGBuK9EgCAc10AV61aRS+//DK9+OKLdPvtt9PWrVvp9ddfp7i2b99O5XJ57jE0NBR7XQAA57QZgrrKu+KKK8L/v27dOvrJT35C3/rWt+iLX/wi2bZN09PT864CR0dHqb+/n12fupJUDwCAC64bjO/74ed4qhgmk0nau3cvbdmyJRw7cuQIHTt2LPyM8LTXmzDISBinPUuUL7yiZlG+pV78BX8vP1Hjl/WT8oW06fK35Gu9EYdA2GTT5gedTjkGMHuJGTsu1OgVuncI3Ug8oXuNkkzzBzeXkjeq4SVjjSkzTb7zirTFXsQMbH1rR9mx4exSOdbzM/6Z09P8cW+WIiInfIKGooIjUjcYPxVvLGqbos5Fg4vJRMRnYhVA9euqyvypGxuVSiW847tv3z7653/+5/Dzu9tuu422bdtG3d3d1NnZSXfddVdY/HAHGADa0WkVwLGxMfrt3/5tOnHiRFjw1qxZExa/X//1Xw/HH3zwQTJNM7wC/GAQGgDggi+AKucnyWQytHPnzvABANDu8LfAAKAtFEAA0BYKIABoCwUQALTVtrPCqS5ERot8kCl3RaIkPzkYeRk5GxQk+J8HiVk+kOTl5N3o5Pmgk90pb5NV58cSfAcocvNyqqs2wO/IICm3auq5hJ+hbU3PMDs2ZWfF9Y7WCuyY7QlhMSI6WeVnWas15RxgfTYdq0dU4MvHLpHhc42Z5cLBU/vKF2aN84X2aotsA9WKJbR8k2ZgC59X2BWBJW+T4fILGxG5Xy4XHETUibnlF/dtAAAXHxRAANAWCiAAaAsFEAC0hQIIANpCAQQAbSXaujS3KM9BxF3+ZEVo1RRxa9xLS7EGPkrhJ+U4xOwyYRYvOd1B2ZP865Fag7k5eZvcMv/ERkTkZPZEDzv2ryl+xrhEXd6m9AQ/lqzKB97L8WMJ8bgS5YQUjCeMRZ1PZPJ9oLyM/Hr8Pj52levis1GeJ1/TNKeE1l92RAspKRKUjB+/kc5jM6KtFReTiYrPzK1/cd8GAHDxQQEEAG2hAAKAtlAAAUBbKIAAoC0UQADQFgogAGirbXOAgfn+Y8HXI6JK0jR6iUZE9qrFNJyn2AX+Z4UbkTNr8tE4yo7K21R622bHTI9vW2U25ZCaNSX1DYsIuKX4TKTXwQfn7G4+g6ZUVsQ/HfOj/L5IT8lzKxpCeykvzWcivZR8/SCdM82SfM7Y3fyy/cUKOzZdl/dxs8IfHz8rn4uuJ4xLLyfqTStN/dqUF00wkUgjYrm59S/u2wAALj4ogACgLRRAANAWCiAAaAsFEAC0hQIIANpq3xiM0fruecQN9ZbRmbmxiNZTEkOYKM2XJx0jLyXFLCJmhRPiLFa5wY6ZE9PyRqX5Vk3Osi5x0Xo/H7Wo9vMHYHZA3iTzill2zB3Ki8t2vco/b2pa3sfJCT4SlDw5yY4FNWHKPuXXrmKHJtbIJ2Oyiz+2xVQ9dgzGSPAncpCLaDnmJeLN7BbRKcsU2qQl+VMiZNmtV24wX1/w3Iv6LgCAixAKIABoCwUQALSFAggA2kIBBABtoQACgLbaNgajYictoydRORiBb0V1pYg3A1vUbX5PSCbULpEXnh3jFy5NVtkxf5YfC83wHUWSDbmVRmKigx3LneDjKr0H5S4zfo7PE1mzZXFZc5wfD9yIKcLqfOTEF8a8668WV3t8A399EXTzXX6UQobvYGMKJ5wTMaOf1JnFTApZr6imLtKllBMR9RJiMKYTxIqnSbG1eetf3LcBAFx8UAABQFsogACgLRRAANAWCiAAaAsFEAC0hQIIANpq2xwga3FdblqLiAFKs8IZ0oxYESuWZqpz+uUZyyY/zmfjDL+bHSu6cubO+/lRdsyvyhlCY3yCHbMmOoUFI/ZTLz99nlvKisu6hV52zE/J2Tgj4I9trZdvGzbyeTnLN9g/wo6NzfBZSsUy+SCbLwTyPE++pgk8aQo2Q1zWEPJ8pi20tKrK603NCJskvz0oSJx+W7x561/ctwEAXHxQAAFAWyiAAKAtFEAA0BYKIABoCwUQALTVtjEY1fEnqs1U6wX5oahb476wN1INfmMsvmNSKDnLb5RryX177G5+fGo1H+9odvaJ6+0TYjL2JfKscOWP8ZGURg//WmvL5dfqL+VjJZcu46M3SiHFt/AyI7JTDWG2s+oMH+u5uiTPvCe1rbJK8r6o2nz8puqk2THHiT/1YeDKb5BEkz+2iRo/loqaoLDsx4qmKU6m9bjvL65vHq4AAUBbKIAAoC0UQADQFgogAGgLBRAAtIUCCADaQgEEAG21bQ4wjG7FyAGKWb8zaIclSVcisnyzfDarVos4BAl+J3gpfmx2UH4t9uZL2LHKNfK0mDd//GV+vUKYsic1K673aI1v79Wblpe9Kj/Mjr1VlzOR/z7J74tUgs9LNoX8oFJI8gHRQlLex0mTf17H588nP2pazEXm41oS3o+W8HISNfmNLLW8cvnI41mBK0AA0BYKIABoCwUQALSFAggA2kIBBABtoQACgLbOKAZz//330/bt2+kP/uAP6KGHHgq/1mg06N5776Vdu3ZRs9mkTZs20SOPPEJ9fXIU4WyRWmgJk2lFtsNy0/zPitSsPANbeppf1hIiMopX8GL9+EoKM20pjZ74O+rINH8se3MVdqzq8jEXZVZo8zRjZ8RlJ+0cOzZcLYrLDk/yLa8si99PqYQbOwaTsuRlO4SYjLSffGnWN8UVZj70o2Y35MetOr+cJU+eRy7T0krxhLFwWaYzW8TkeGd+BfiTn/yE/vIv/5LWrFkz7+v33HMPPf3007R7927av38/DQ8P0+bNm+M+DQDAOROrAM7OztJv/dZv0eOPP05dXf/VPLNcLtMTTzxB3/zmN2nDhg20bt06evLJJ+nf/u3f6ODBg2dzuwEAzk8BvOOOO+jzn/88bdy4cd7XDx8+TI7jzPv66tWraXBwkA4cONByXerX5JmZmXkPAIC2/AxQfbb30ksvhb8Cf9jIyAilUikqlUrzvq4+/1NjrezYsYP+5E/+5HQ3AwDgo70CHBoaCm94fPe736VMRv5QerHUTRT1q/Oph3oOAIC2K4DqV9yxsTH65Cc/SYlEInyoGx0PP/xw+P/VlZ5t2zQ9PX8WlNHRUerv72+5znQ6TZ2dnfMeAABt9yvwTTfdRK+88sq8r33pS18KP+f7oz/6IxoYGKBkMkl79+6lLVu2hONHjhyhY8eO0fr1689ON5gzaGZxJst6aX5hX5gtS0mX+ShLclY+BH4vH5dwCvzzZkfleE3HUX6sUeNnJFOOWXycpXtllR3rz/IRmSgTjbw4fvj4ADtmT8q/rRhCvMPJ8ceuno7Id/DJnMjuNvkEH4M54vAxpMCWr2mkqIvZkM/jhBh1Cc7JbIxBRHMbp7P183rCLI6xC2ChUKBrrrlm3tfy+TwtWbJk7uu33XYbbdu2jbq7u8OrubvuuissfjfccMPpPBUAwIXXD/DBBx8k0zTDK8APBqEBAC66Arhv3755/1Y3R3bu3Bk+AADaGf4WGAC0hQIIANpCAQQAbaEAAoC22ndWOBVJMs5yDvAMSFklLyX/HElW+CxZohbxxDl+yiwvJcwcNiLn5oo/D2LlvZRkhc/VHTlyJTv2RlJeryF0/kpF/Il4sSzMnhcxs1i9lz+pGkIXN0PqvRa2vOJf0KXZcXHZKYc/fnWX35FGMyI4J3VXa8pvLovv7kWGH++9E7WssBvEHKAvzJj4QbgCBABtoQACgLZQAAFAWyiAAKAtFEAA0BYKIABoq21jMKqFTlQbndNfafRzxhlrCm2pFNPlF05PyhvVFJa9vI+PUhwpy9mPznf49Xa9IbdqMjw+t2C4QqYhkF9rkObjHW5eztDU+vgWXs1u+USyS/w251fwLbyu7JajLFd1tO6CrhSladSIaMzm+2JO1vk+W2Yt4k0jRHcS9agYDL+sxXfvIj+qpVUH/7zNHuF8UutOtx73fXm5U3AFCADaQgEEAG2hAAKAtlAAAUBbKIAAoC0UQADQFgogAGirbXOAnIgOROeMlGWKmrrP7uB/ziTr8gvyRrLsmLOUf+KeFfPnZv6w8bVL+EFD7kGUHeen6mwW+W2q9ss7yi7xY80lEbmuHj6I1tEh9HEioqu7ptixqzr5LN/HMmPiejMGP23mCadLXHbc7uDHxviMYGY2ql8cP56STxlKzfLnqsmfEuTn5G1yhelDvXzEcT/DeoArQADQFgogAGgLBRAAtIUCCADaQgEEAG2hAAKAti64GExwnmaFk2ajC4yI2/wZ/l59Su48RR1H+Z9RJ1fycZW+grzixFo+wjFxKR/BUHzhIGSz/DR3lwpxE2Vpht/mQkKOsnQI/ZikMaUnWYkVZWkEfAsuZdLj9+PbtV5x2ZdHL2HH0kP886bKFFtqRs6UJIR2WG6aPyfcrPz+aHYLbbY6+f2veDPMvlhkncAVIABoCwUQALSFAggA2kIBBABtoQACgLZQAAFAWxdeDCai84rUHSKqk0wQM+piRM12FnO2OaXzmMeOjb3Gt09xrpNnHbumm+9yUi/KM7CNN/j4TcLku3f0Zfi4SZSqK89yl7Ucdqzs8R11lFmPX3fS5Pf/lJOLvc0/G18uLlt5mz+2nSPCzG58CilkevyyyWrEG0R4f3gpYWa3bnm1bi8fdUkK51P4vNzw4iaFwxUgAOgLBRAAtIUCCADaQgEEAG2hAAKAtlAAAUBbKIAAoK22zQGqfFyrjFxgxu+Hdc4mlIvIHEndmDKTfM5MSY/zbaCWGnwO7VixT96m1fxGZxN8pk6ZqPE5QM/nj89EXc7N1Zp8myfHlQOgxbyce5R4Pn8dYArhUTtim2Zm+fyhcUzOJhZ/wY9lpvhjl6zKJ6Mh5AC9jHw95OT5cbvEH/f6clduw5Xjzze7Krcco0Rwel//EFwBAoC2UAABQFsogACgLRRAANAWCiAAaAsFEAC01cYxGCNW5CWqvZREbJd1BhmaTJmPJuT+Y1xctrp6KTtm2fxGLX9e3nfD4yvYsWa3HM0JhIiBaUu9v8TVkiEkOAxHfj0nrQI7FjEpnPi8vvAOsZryNhUm+LHsuBxXSU/zx8BqyMdHYhf5F9QoybEeu1NoedUlnBMFOVblecI5I51P4crPLNyGK0AA0BYKIABoCwUQALSFAggA2kIBBABtoQACgLZQAAFAW22cA2w9BaaU2Yoaj5pSU0oUmS4/mpmSs0iF1/hAmNHgpwRUxj7JH6LsGP+8Pa/I7aGy43ymyy7I02J6GX5ZN0Ox+Ra/XsuR93Gyxh94qy6fNIHwvBTznAift+bGnqKVfP4b/DR/IleXye2jGt1m7PeHJ6zazfPbK8wo+/56q/L5Junqn2m9zlqTji9ieVwBAoC2UAABQFsogACgLRRAANAWCiAAaKvt7gIHwft3kzy7Ee/umbTuqHIvrDsQ7vi5EXcoXY9vR2L4cqsSr8lPiuQJ3WBcl19OCUi4k+vI3UY84a6pdwaTVkl3gSnijqvh8Hd6AzfiLrAwkZPEFCYYev95z9FdYIu/XesJ+yEcF7qrBBHvD+nl+g3heWvyOe7XhTLkycdG3e2Vvn6qnnCMIOo7PmLHjx+ngYGB870ZAHARGBoaohUrVlw4BdD3fRoeHqZCoUCGYdDMzExYENUL6ezsPN+b17awnxYH+0mP/RQEAVUqFVq+fDmZpnnh/AqsNrZVxVYH4UI8EB817KfFwX5anAt5PxWLxcjvwU0QANAWCiAAaKvtC2A6naavf/3r4X+Bh/20ONhPi5PWZD+13U0QAICPSttfAQIAnCsogACgLRRAANAWCiAAaKvtC+DOnTvpsssuo0wmQ9dffz39+Mc/Jp298MIL9IUvfCFMuKu/lPn+978/b1zd07rvvvto2bJllM1maePGjfTWW2+RTnbs2EHXXXdd+NdEvb29dOutt9KRI0fmfU+j0aA77riDlixZQh0dHbRlyxYaHR0lnTz66KO0Zs2aubDz+vXr6Z/+6Z+02kdtXQD/7u/+jrZt2xbejn/ppZdo7dq1tGnTJhobGyNdVavVcD+oHwytfOMb36CHH36YHnvsMXrxxRcpn8+H+0ydzLrYv39/+MY9ePAgPfvss+Q4Dt18883hvjvlnnvuoaeffpp2794dfr/688vNmzeTTlasWEH3338/HT58mA4dOkQbNmygW265hV577TV99lHQxj71qU8Fd9xxx9y/Pc8Lli9fHuzYseO8ble7UIdvz549c//2fT/o7+8PHnjggbmvTU9PB+l0Ovjbv/3bQFdjY+HkKcH+/fvn9kkymQx279499z1vvPFG+D0HDhwIdNbV1RX81V/9lTb7qG2vAG3bDn8yqV/hPvh3wurfBw4cOK/b1q7eeecdGhkZmbfP1N9Dqo8OdN5n5XI5/G93d3f4X3VeqavCD+6n1atX0+DgoLb7yfM82rVrV3iVrH4V1mUftV0zhFPGx8fDg9LX1zfv6+rfb7755nnbrnamip/Sap+dGtON6i50991304033kjXXHNN+DW1L1KpFJVKJdJ9P73yyithwVMfkajP+fbs2UNXX301vfzyy1rso7YtgABng/os8NVXX6Uf/ehH53tT2tKqVavCYqeukv/+7/+etm7dGn7ep4u2/RW4p6eHLMtacNdJ/bu/v/+8bVc7O7VfsM/ed+edd9IPf/hDev755+e1WFP7Qn3EMj09Tbrvp1QqRVdccQWtW7cuvHuubrB961vf0mYfme18YNRB2bt377xfZ9S/1SU7LLRy5crw5PzgPlONLdXdYJ32mbo/pIqf+nXuueeeC/fLB6nzKplMzttPKiZz7NgxrfZTK+o91mw29dlHQRvbtWtXeAfzqaeeCl5//fXgy1/+clAqlYKRkZFAV5VKJfjpT38aPtTh++Y3vxn+/6NHj4bj999/f7iPfvCDHwQ/+9nPgltuuSVYuXJlUK/XA13cfvvtQbFYDPbt2xecOHFi7lGr1ea+5ytf+UowODgYPPfcc8GhQ4eC9evXhw+dfPWrXw3vjL/zzjvhuaL+bRhG8C//8i/a7KO2LoDKt7/97fAgpFKpMBZz8ODBQGfPP/98WPg+/Ni6detcFOZrX/ta0NfXF/7wuOmmm4IjR44EOmm1f9TjySefnPse9QPh93//98PYRy6XC37jN34jLJI6+d3f/d3g0ksvDd9bS5cuDc+VU8VPl32EdlgAoK22/QwQAOBcQwEEAG2hAAKAtlAAAUBbKIAAoC0UQADQFgogAGgLBRAAtIUCCADaQgEEAG2hAAKAtlAAAYB09f8Ba68LFn9f83UAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(lfw_people.images[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d50bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!dir \"../data/external/wind-power-generation-data\"\n",
    "#lfw_people.images[1][0]['imageHeight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ba18022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # input_shape=(3, H, W)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 12 * 9, 128)  # 64 feature maps, 12x9 size\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a880e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data, target in train_loader:\n",
    "        # Ensure that the target is in the correct format (class indices) for compatibility with CrossEntropyLoss.\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        target = target.long()  # Ensure target is of type torch.long\n",
    "        if len(target.size()) > 1:\n",
    "                target = target.squeeze()  # Remove extra dimensions\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            target = target.long()  # Ensure target is of type torch.long\n",
    "            if len(target.size()) > 1:\n",
    "                target = target.squeeze()  # Remove extra dimensions\n",
    "            outputs = model(data)\n",
    "            test_loss += criterion(outputs, target).item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return test_loss, accuracy\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18083824",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)  # Set your desired seed value here\n",
    "    \n",
    "# Hyperparameters and device setup\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "learning_rate = 0.0001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Data preparation\n",
    "X_train, X_test, y_train, y_test = train_test_split(lfw_people.images, lfw_people.target, test_size=0.2, random_state=42)\n",
    "target_names = lfw_people.target_names\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train, transform_train)\n",
    "test_dataset = CustomDataset(X_test, y_test, transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07369372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = CNN(num_classes=len(target_names)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for param in model.parameters():\n",
    "    param.grad = None\n",
    "\n",
    "# Training and testing loop\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "accuracies = []\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "best_test_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# Definiowanie zakresów hiperparametrów\n",
    "param_space = {\n",
    "    \"batch_size\": [32, 64, 128, 256],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.001, 0.0001],\n",
    "    \"dropout_rate\": [0.25, 0.5]\n",
    "}\n",
    "\n",
    "def run_experiment(params):\n",
    "    # Aktualizuj dropout w modelu\n",
    "    model.dropout.p = params['dropout_rate']\n",
    "\n",
    "    # Przygotuj dataloadery z nowym batch_size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "\n",
    "    # Aktualizuj optimizer z nowym learning_rate\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "    # Trening modelu\n",
    "    best_test_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "        test_loss, accuracy = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            torch.save(model.state_dict(), f\"best_model_hyperparameter.pth\")\n",
    "\n",
    "    return best_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c1289c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with params: {'batch_size': 32, 'learning_rate': 0.1, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 95.5701, Test Loss: 17.9603, Accuracy: 0.4341\n",
      "Epoch 2/50, Train Loss: 4.3263, Test Loss: 2.7217, Accuracy: 0.1047\n",
      "Epoch 3/50, Train Loss: 2.6610, Test Loss: 2.5014, Accuracy: 0.1822\n",
      "Epoch 4/50, Train Loss: 3.8970, Test Loss: 4.5801, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 4.5185, Test Loss: 4.7924, Accuracy: 0.0426\n",
      "Epoch 6/50, Train Loss: 5.9645, Test Loss: 6.0463, Accuracy: 0.0853\n",
      "Epoch 7/50, Train Loss: 5.8634, Test Loss: 6.1615, Accuracy: 0.1047\n",
      "Epoch 8/50, Train Loss: 5.9676, Test Loss: 7.4432, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 8.7156, Test Loss: 9.5493, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 8.9198, Test Loss: 10.0626, Accuracy: 0.0736\n",
      "Epoch 11/50, Train Loss: 9.2797, Test Loss: 7.9041, Accuracy: 0.1822\n",
      "Epoch 12/50, Train Loss: 9.6207, Test Loss: 10.7960, Accuracy: 0.1822\n",
      "Epoch 13/50, Train Loss: 9.0793, Test Loss: 7.3330, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 9.0237, Test Loss: 11.0758, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 11.3777, Test Loss: 12.2009, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 11.1175, Test Loss: 10.9995, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 10.6735, Test Loss: 11.8383, Accuracy: 0.1047\n",
      "Epoch 18/50, Train Loss: 13.1890, Test Loss: 12.8059, Accuracy: 0.1047\n",
      "Epoch 19/50, Train Loss: 10.8104, Test Loss: 9.1483, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 11.0744, Test Loss: 11.1906, Accuracy: 0.0853\n",
      "Epoch 21/50, Train Loss: 13.0406, Test Loss: 10.8286, Accuracy: 0.0853\n",
      "Epoch 22/50, Train Loss: 12.1901, Test Loss: 10.6439, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 11.6873, Test Loss: 9.4250, Accuracy: 0.1822\n",
      "Epoch 24/50, Train Loss: 4925.5151, Test Loss: 15.1002, Accuracy: 0.1822\n",
      "Epoch 25/50, Train Loss: 17.3169, Test Loss: 15.4394, Accuracy: 0.1822\n",
      "Epoch 26/50, Train Loss: 17.3079, Test Loss: 15.1655, Accuracy: 0.0426\n",
      "Epoch 27/50, Train Loss: 12.2689, Test Loss: 10.1956, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 12.8485, Test Loss: 12.4599, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 13.4129, Test Loss: 10.9313, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 10.1697, Test Loss: 7.8957, Accuracy: 0.0736\n",
      "Epoch 31/50, Train Loss: 11.8358, Test Loss: 12.5326, Accuracy: 0.0736\n",
      "Epoch 32/50, Train Loss: 13.5155, Test Loss: 12.2891, Accuracy: 0.0853\n",
      "Epoch 33/50, Train Loss: 56536.9583, Test Loss: 13.1734, Accuracy: 0.0504\n",
      "Epoch 34/50, Train Loss: 16.0311, Test Loss: 15.1583, Accuracy: 0.1822\n",
      "Epoch 35/50, Train Loss: 16.8528, Test Loss: 14.8085, Accuracy: 0.1822\n",
      "Epoch 36/50, Train Loss: 14.3896, Test Loss: 9.6797, Accuracy: 0.1822\n",
      "Epoch 37/50, Train Loss: 9.0375, Test Loss: 8.4655, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 12.1752, Test Loss: 13.0766, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 16.0316, Test Loss: 16.1208, Accuracy: 0.1047\n",
      "Epoch 40/50, Train Loss: 18.7358, Test Loss: 19.4856, Accuracy: 0.1047\n",
      "Epoch 41/50, Train Loss: 20.7879, Test Loss: 19.0922, Accuracy: 0.1047\n",
      "Epoch 42/50, Train Loss: 20.0148, Test Loss: 20.2128, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 21.3121, Test Loss: 20.0188, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 20.2429, Test Loss: 17.3863, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 16.3785, Test Loss: 7120333.2837, Accuracy: 0.0853\n",
      "Epoch 46/50, Train Loss: 736806.2082, Test Loss: 18.3007, Accuracy: 0.0853\n",
      "Epoch 47/50, Train Loss: 19.7552, Test Loss: 20.3098, Accuracy: 0.0504\n",
      "Epoch 48/50, Train Loss: 18.7000, Test Loss: 13.8807, Accuracy: 0.0504\n",
      "Epoch 49/50, Train Loss: 12.8276, Test Loss: 11.4930, Accuracy: 0.1047\n",
      "Epoch 50/50, Train Loss: 9.7947, Test Loss: 6.1483, Accuracy: 0.1047\n",
      "Running experiment with params: {'batch_size': 32, 'learning_rate': 0.1, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 6.4631, Test Loss: 6.3039, Accuracy: 0.0736\n",
      "Epoch 2/50, Train Loss: 6.9621, Test Loss: 6.6218, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 7.8073, Test Loss: 7.6528, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 8.6189, Test Loss: 7.4314, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 9.1980, Test Loss: 9.3819, Accuracy: 0.1822\n",
      "Epoch 6/50, Train Loss: 11.5369, Test Loss: 10.8295, Accuracy: 0.1822\n",
      "Epoch 7/50, Train Loss: 11.6276, Test Loss: 9.6144, Accuracy: 0.1822\n",
      "Epoch 8/50, Train Loss: 9.3923, Test Loss: 6.5203, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 8.2919, Test Loss: 8.1005, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 10.3650, Test Loss: 9.8438, Accuracy: 0.0853\n",
      "Epoch 11/50, Train Loss: 11.0769, Test Loss: 10.1363, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 11.9057, Test Loss: 12.5677, Accuracy: 0.0426\n",
      "Epoch 13/50, Train Loss: 14.4161, Test Loss: 14.8560, Accuracy: 0.0736\n",
      "Epoch 14/50, Train Loss: 14.9847, Test Loss: 14.5997, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 15.4971, Test Loss: 16.0280, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 16.5433, Test Loss: 15.9410, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 15.5743, Test Loss: 13.3107, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 12.6088, Test Loss: 11.5892, Accuracy: 0.0426\n",
      "Epoch 19/50, Train Loss: 11.3844, Test Loss: 10.7796, Accuracy: 0.0853\n",
      "Epoch 20/50, Train Loss: 12.1247, Test Loss: 10.9620, Accuracy: 0.0853\n",
      "Epoch 21/50, Train Loss: 10.8611, Test Loss: 8.0865, Accuracy: 0.0736\n",
      "Epoch 22/50, Train Loss: 7.7626, Test Loss: 7.6674, Accuracy: 0.1822\n",
      "Epoch 23/50, Train Loss: 9.0584, Test Loss: 7.8791, Accuracy: 0.1822\n",
      "Epoch 24/50, Train Loss: 9.6282, Test Loss: 9.9272, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 12.3110, Test Loss: 11.7919, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 13.0164, Test Loss: 12.0521, Accuracy: 0.1047\n",
      "Epoch 27/50, Train Loss: 15.1583, Test Loss: 15.7438, Accuracy: 0.1047\n",
      "Epoch 28/50, Train Loss: 17.4790, Test Loss: 16.1676, Accuracy: 0.1047\n",
      "Epoch 29/50, Train Loss: 15.7146, Test Loss: 12.2590, Accuracy: 0.1047\n",
      "Epoch 30/50, Train Loss: 13.1809, Test Loss: 11.2540, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 13.2511, Test Loss: 11.2128, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 13.9338, Test Loss: 12.3503, Accuracy: 0.1822\n",
      "Epoch 33/50, Train Loss: 14.8965, Test Loss: 12.1868, Accuracy: 0.1822\n",
      "Epoch 34/50, Train Loss: 13.7703, Test Loss: 9.6970, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 13.1090, Test Loss: 10.8717, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 15.3191, Test Loss: 14.1130, Accuracy: 0.0853\n",
      "Epoch 37/50, Train Loss: 16.6064, Test Loss: 12.5483, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 15.6470, Test Loss: 13.8447, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 15.6381, Test Loss: 13.3275, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 14.8420, Test Loss: 14.8709, Accuracy: 0.0504\n",
      "Epoch 41/50, Train Loss: 17.9927, Test Loss: 17.8437, Accuracy: 0.0504\n",
      "Epoch 42/50, Train Loss: 17.7856, Test Loss: 14.8222, Accuracy: 0.0504\n",
      "Epoch 43/50, Train Loss: 11.8679, Test Loss: 7.4431, Accuracy: 0.0736\n",
      "Epoch 44/50, Train Loss: 9.1960, Test Loss: 9.3099, Accuracy: 0.0736\n",
      "Epoch 45/50, Train Loss: 9.8468, Test Loss: 9.0242, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 10.4928, Test Loss: 10.3004, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 11.7978, Test Loss: 11.3956, Accuracy: 0.1822\n",
      "Epoch 48/50, Train Loss: 12.5381, Test Loss: 11.6219, Accuracy: 0.1822\n",
      "Epoch 49/50, Train Loss: 12.1334, Test Loss: 11.1775, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 12.3543, Test Loss: 11.1979, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 32, 'learning_rate': 0.01, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 12.0087, Test Loss: 10.9162, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 11.9649, Test Loss: 10.5190, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 11.3684, Test Loss: 10.0097, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 10.5939, Test Loss: 9.4963, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 10.1935, Test Loss: 9.0473, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 9.8964, Test Loss: 8.7485, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 9.3704, Test Loss: 8.6185, Accuracy: 0.1822\n",
      "Epoch 8/50, Train Loss: 9.4873, Test Loss: 8.5064, Accuracy: 0.1822\n",
      "Epoch 9/50, Train Loss: 9.5932, Test Loss: 8.2165, Accuracy: 0.1822\n",
      "Epoch 10/50, Train Loss: 8.8217, Test Loss: 7.7811, Accuracy: 0.1822\n",
      "Epoch 11/50, Train Loss: 8.2996, Test Loss: 7.3385, Accuracy: 0.1822\n",
      "Epoch 12/50, Train Loss: 7.8914, Test Loss: 6.9381, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 7.3951, Test Loss: 6.5781, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 7.3479, Test Loss: 6.2513, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 6.6927, Test Loss: 5.9589, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 6.3520, Test Loss: 5.7259, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 6.1078, Test Loss: 5.6026, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 6.2808, Test Loss: 5.6271, Accuracy: 0.0736\n",
      "Epoch 19/50, Train Loss: 6.0669, Test Loss: 5.7548, Accuracy: 0.0736\n",
      "Epoch 20/50, Train Loss: 6.6074, Test Loss: 5.8749, Accuracy: 0.0736\n",
      "Epoch 21/50, Train Loss: 6.2478, Test Loss: 5.8951, Accuracy: 0.0736\n",
      "Epoch 22/50, Train Loss: 6.6118, Test Loss: 5.8097, Accuracy: 0.0736\n",
      "Epoch 23/50, Train Loss: 6.0990, Test Loss: 5.7110, Accuracy: 0.0736\n",
      "Epoch 24/50, Train Loss: 6.0303, Test Loss: 5.7098, Accuracy: 0.0426\n",
      "Epoch 25/50, Train Loss: 6.4801, Test Loss: 5.7899, Accuracy: 0.0426\n",
      "Epoch 26/50, Train Loss: 6.3412, Test Loss: 5.8452, Accuracy: 0.0426\n",
      "Epoch 27/50, Train Loss: 6.5726, Test Loss: 5.7878, Accuracy: 0.0426\n",
      "Epoch 28/50, Train Loss: 6.0511, Test Loss: 5.5857, Accuracy: 0.0426\n",
      "Epoch 29/50, Train Loss: 5.8071, Test Loss: 5.2670, Accuracy: 0.0426\n",
      "Epoch 30/50, Train Loss: 5.4707, Test Loss: 4.9335, Accuracy: 0.0426\n",
      "Epoch 31/50, Train Loss: 5.2438, Test Loss: 4.7442, Accuracy: 0.0426\n",
      "Epoch 32/50, Train Loss: 5.1966, Test Loss: 4.7820, Accuracy: 0.0853\n",
      "Epoch 33/50, Train Loss: 5.3178, Test Loss: 4.9765, Accuracy: 0.0853\n",
      "Epoch 34/50, Train Loss: 5.5892, Test Loss: 5.2200, Accuracy: 0.0853\n",
      "Epoch 35/50, Train Loss: 6.0597, Test Loss: 5.4479, Accuracy: 0.0853\n",
      "Epoch 36/50, Train Loss: 6.0841, Test Loss: 5.6329, Accuracy: 0.0853\n",
      "Epoch 37/50, Train Loss: 6.2342, Test Loss: 5.7642, Accuracy: 0.1047\n",
      "Epoch 38/50, Train Loss: 6.3812, Test Loss: 5.8384, Accuracy: 0.1047\n",
      "Epoch 39/50, Train Loss: 6.4407, Test Loss: 5.8537, Accuracy: 0.1047\n",
      "Epoch 40/50, Train Loss: 6.6714, Test Loss: 5.8086, Accuracy: 0.1047\n",
      "Epoch 41/50, Train Loss: 6.4067, Test Loss: 5.7037, Accuracy: 0.1047\n",
      "Epoch 42/50, Train Loss: 6.3228, Test Loss: 5.5407, Accuracy: 0.1047\n",
      "Epoch 43/50, Train Loss: 6.1490, Test Loss: 5.3245, Accuracy: 0.1047\n",
      "Epoch 44/50, Train Loss: 5.9581, Test Loss: 5.0672, Accuracy: 0.1047\n",
      "Epoch 45/50, Train Loss: 6.1049, Test Loss: 4.7935, Accuracy: 0.1047\n",
      "Epoch 46/50, Train Loss: 5.4192, Test Loss: 4.5431, Accuracy: 0.1047\n",
      "Epoch 47/50, Train Loss: 5.3050, Test Loss: 4.3666, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 5.3510, Test Loss: 4.2980, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 5.1696, Test Loss: 4.3309, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 5.4893, Test Loss: 4.4315, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 32, 'learning_rate': 0.01, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 5.3481, Test Loss: 4.5805, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 5.6943, Test Loss: 4.7453, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 5.9820, Test Loss: 4.9110, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 5.9088, Test Loss: 5.0688, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 6.0725, Test Loss: 5.2133, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 6.2592, Test Loss: 5.3413, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 6.5279, Test Loss: 5.4504, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 6.6414, Test Loss: 5.5394, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 6.5177, Test Loss: 5.6078, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 6.6313, Test Loss: 5.6583, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 6.6505, Test Loss: 5.6921, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 6.6734, Test Loss: 5.7087, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 6.7599, Test Loss: 5.7064, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 6.6308, Test Loss: 5.6826, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 6.6200, Test Loss: 5.6342, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 6.5174, Test Loss: 5.5572, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 6.5635, Test Loss: 5.4505, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 6.2919, Test Loss: 5.3142, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 6.4041, Test Loss: 5.1515, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 5.9973, Test Loss: 4.9657, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 5.8952, Test Loss: 4.7585, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 5.7884, Test Loss: 4.5330, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 5.3096, Test Loss: 4.2951, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 4.9952, Test Loss: 4.0648, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 4.8095, Test Loss: 3.8901, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 4.6513, Test Loss: 3.8505, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 4.7707, Test Loss: 4.0015, Accuracy: 0.0736\n",
      "Epoch 28/50, Train Loss: 4.9248, Test Loss: 4.2876, Accuracy: 0.0736\n",
      "Epoch 29/50, Train Loss: 5.2538, Test Loss: 4.5919, Accuracy: 0.0736\n",
      "Epoch 30/50, Train Loss: 5.4368, Test Loss: 4.8291, Accuracy: 0.0736\n",
      "Epoch 31/50, Train Loss: 5.7614, Test Loss: 4.9584, Accuracy: 0.0736\n",
      "Epoch 32/50, Train Loss: 5.7800, Test Loss: 4.9580, Accuracy: 0.0853\n",
      "Epoch 33/50, Train Loss: 5.8285, Test Loss: 4.8179, Accuracy: 0.0853\n",
      "Epoch 34/50, Train Loss: 5.3551, Test Loss: 4.5442, Accuracy: 0.0853\n",
      "Epoch 35/50, Train Loss: 5.1048, Test Loss: 4.1829, Accuracy: 0.0853\n",
      "Epoch 36/50, Train Loss: 4.6257, Test Loss: 3.8448, Accuracy: 0.0853\n",
      "Epoch 37/50, Train Loss: 4.3343, Test Loss: 3.6679, Accuracy: 0.1047\n",
      "Epoch 38/50, Train Loss: 4.2226, Test Loss: 3.6865, Accuracy: 0.1047\n",
      "Epoch 39/50, Train Loss: 4.2875, Test Loss: 3.7988, Accuracy: 0.1047\n",
      "Epoch 40/50, Train Loss: 4.4617, Test Loss: 3.8987, Accuracy: 0.1047\n",
      "Epoch 41/50, Train Loss: 4.5870, Test Loss: 3.9436, Accuracy: 0.1047\n",
      "Epoch 42/50, Train Loss: 4.4847, Test Loss: 3.9484, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 4.4940, Test Loss: 3.9513, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 4.4968, Test Loss: 3.9753, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 4.5772, Test Loss: 4.0093, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 4.5604, Test Loss: 4.0222, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 4.6094, Test Loss: 3.9897, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 4.5712, Test Loss: 3.9057, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 4.4206, Test Loss: 3.7853, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 4.3208, Test Loss: 3.6837, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 32, 'learning_rate': 0.001, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 4.2419, Test Loss: 3.6808, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 4.2385, Test Loss: 3.6779, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 4.2844, Test Loss: 3.6749, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 4.2614, Test Loss: 3.6718, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 4.2909, Test Loss: 3.6687, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 4.2801, Test Loss: 3.6655, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 4.2794, Test Loss: 3.6618, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 4.1677, Test Loss: 3.6574, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 4.2178, Test Loss: 3.6519, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 4.1801, Test Loss: 3.6448, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 4.2465, Test Loss: 3.6355, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 4.2304, Test Loss: 3.6237, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 4.3561, Test Loss: 3.6088, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 4.3331, Test Loss: 3.5909, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 4.1235, Test Loss: 3.5702, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 4.1992, Test Loss: 3.5472, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 4.0559, Test Loss: 3.5223, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 4.0189, Test Loss: 3.4960, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 3.9940, Test Loss: 3.4687, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 3.9661, Test Loss: 3.4406, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 3.9176, Test Loss: 3.4121, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 3.9495, Test Loss: 3.3832, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 3.9597, Test Loss: 3.3543, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 3.8859, Test Loss: 3.3254, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 3.8144, Test Loss: 3.2966, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 3.7584, Test Loss: 3.2681, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 3.7846, Test Loss: 3.2401, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 3.7932, Test Loss: 3.2126, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 3.7103, Test Loss: 3.1857, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 3.6325, Test Loss: 3.1595, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 3.6685, Test Loss: 3.1341, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 3.6006, Test Loss: 3.1094, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 3.5632, Test Loss: 3.0855, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 3.5985, Test Loss: 3.0623, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 3.5777, Test Loss: 3.0398, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 3.5097, Test Loss: 3.0178, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 3.4443, Test Loss: 2.9962, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 3.5190, Test Loss: 2.9748, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 3.4829, Test Loss: 2.9534, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 3.4775, Test Loss: 2.9318, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 3.4259, Test Loss: 2.9096, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 3.3400, Test Loss: 2.8868, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 3.3862, Test Loss: 2.8633, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 3.2878, Test Loss: 2.8390, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 3.3063, Test Loss: 2.8139, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 3.3044, Test Loss: 2.7884, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 3.2434, Test Loss: 2.7625, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 3.2608, Test Loss: 2.7367, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 3.1426, Test Loss: 2.7111, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 3.1618, Test Loss: 2.6859, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 32, 'learning_rate': 0.001, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 3.1483, Test Loss: 2.6697, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 3.1965, Test Loss: 2.6535, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 3.0556, Test Loss: 2.6373, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 3.0902, Test Loss: 2.6211, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 3.0831, Test Loss: 2.6050, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 3.0119, Test Loss: 2.5890, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 3.0536, Test Loss: 2.5732, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 2.9703, Test Loss: 2.5575, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 2.9588, Test Loss: 2.5420, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 2.9797, Test Loss: 2.5268, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 3.0366, Test Loss: 2.5119, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 2.9006, Test Loss: 2.4973, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 3.0523, Test Loss: 2.4830, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 2.8649, Test Loss: 2.4691, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 2.8637, Test Loss: 2.4557, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 2.9528, Test Loss: 2.4427, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 2.8323, Test Loss: 2.4303, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 2.8312, Test Loss: 2.4183, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 2.8651, Test Loss: 2.4070, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 2.8479, Test Loss: 2.3963, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 2.8758, Test Loss: 2.3862, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 2.7739, Test Loss: 2.3768, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 2.7620, Test Loss: 2.3682, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 2.7496, Test Loss: 2.3603, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 2.7890, Test Loss: 2.3531, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 2.7736, Test Loss: 2.3469, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 2.7691, Test Loss: 2.3414, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 2.7301, Test Loss: 2.3369, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 2.7636, Test Loss: 2.3332, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 2.7051, Test Loss: 2.3304, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 2.7062, Test Loss: 2.3286, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 2.7503, Test Loss: 2.3277, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 2.6944, Test Loss: 2.3278, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 2.7778, Test Loss: 2.3288, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 2.6965, Test Loss: 2.3307, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 2.7453, Test Loss: 2.3336, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 2.6979, Test Loss: 2.3374, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 2.6984, Test Loss: 2.3421, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 2.7014, Test Loss: 2.3476, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 2.7527, Test Loss: 2.3539, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 2.7888, Test Loss: 2.3611, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 2.7134, Test Loss: 2.3689, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 2.7235, Test Loss: 2.3775, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 2.7297, Test Loss: 2.3866, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 2.7827, Test Loss: 2.3963, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 2.7431, Test Loss: 2.4065, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 2.7974, Test Loss: 2.4171, Accuracy: 0.0853\n",
      "Epoch 48/50, Train Loss: 2.8061, Test Loss: 2.4281, Accuracy: 0.0853\n",
      "Epoch 49/50, Train Loss: 2.7788, Test Loss: 2.4393, Accuracy: 0.0853\n",
      "Epoch 50/50, Train Loss: 2.7919, Test Loss: 2.4506, Accuracy: 0.0853\n",
      "Running experiment with params: {'batch_size': 32, 'learning_rate': 0.0001, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 2.7861, Test Loss: 2.4523, Accuracy: 0.0853\n",
      "Epoch 2/50, Train Loss: 2.8251, Test Loss: 2.4540, Accuracy: 0.0853\n",
      "Epoch 3/50, Train Loss: 2.8040, Test Loss: 2.4556, Accuracy: 0.0853\n",
      "Epoch 4/50, Train Loss: 2.8037, Test Loss: 2.4572, Accuracy: 0.0853\n",
      "Epoch 5/50, Train Loss: 2.7992, Test Loss: 2.4586, Accuracy: 0.0853\n",
      "Epoch 6/50, Train Loss: 2.8442, Test Loss: 2.4600, Accuracy: 0.0853\n",
      "Epoch 7/50, Train Loss: 2.8278, Test Loss: 2.4612, Accuracy: 0.0853\n",
      "Epoch 8/50, Train Loss: 2.8414, Test Loss: 2.4623, Accuracy: 0.0853\n",
      "Epoch 9/50, Train Loss: 2.7959, Test Loss: 2.4633, Accuracy: 0.0853\n",
      "Epoch 10/50, Train Loss: 2.8022, Test Loss: 2.4641, Accuracy: 0.0853\n",
      "Epoch 11/50, Train Loss: 2.7942, Test Loss: 2.4647, Accuracy: 0.0853\n",
      "Epoch 12/50, Train Loss: 2.7972, Test Loss: 2.4651, Accuracy: 0.0853\n",
      "Epoch 13/50, Train Loss: 2.8416, Test Loss: 2.4652, Accuracy: 0.0853\n",
      "Epoch 14/50, Train Loss: 2.8469, Test Loss: 2.4651, Accuracy: 0.0853\n",
      "Epoch 15/50, Train Loss: 2.7983, Test Loss: 2.4648, Accuracy: 0.0853\n",
      "Epoch 16/50, Train Loss: 2.8756, Test Loss: 2.4642, Accuracy: 0.0853\n",
      "Epoch 17/50, Train Loss: 2.7956, Test Loss: 2.4635, Accuracy: 0.0853\n",
      "Epoch 18/50, Train Loss: 2.8424, Test Loss: 2.4626, Accuracy: 0.0853\n",
      "Epoch 19/50, Train Loss: 2.7876, Test Loss: 2.4615, Accuracy: 0.0853\n",
      "Epoch 20/50, Train Loss: 2.8278, Test Loss: 2.4603, Accuracy: 0.0853\n",
      "Epoch 21/50, Train Loss: 2.7871, Test Loss: 2.4589, Accuracy: 0.0853\n",
      "Epoch 22/50, Train Loss: 2.7839, Test Loss: 2.4575, Accuracy: 0.0853\n",
      "Epoch 23/50, Train Loss: 2.8265, Test Loss: 2.4560, Accuracy: 0.0853\n",
      "Epoch 24/50, Train Loss: 2.7895, Test Loss: 2.4545, Accuracy: 0.0853\n",
      "Epoch 25/50, Train Loss: 2.7875, Test Loss: 2.4529, Accuracy: 0.0853\n",
      "Epoch 26/50, Train Loss: 2.8172, Test Loss: 2.4512, Accuracy: 0.0853\n",
      "Epoch 27/50, Train Loss: 2.7858, Test Loss: 2.4496, Accuracy: 0.0853\n",
      "Epoch 28/50, Train Loss: 2.7808, Test Loss: 2.4479, Accuracy: 0.0853\n",
      "Epoch 29/50, Train Loss: 2.7847, Test Loss: 2.4462, Accuracy: 0.0853\n",
      "Epoch 30/50, Train Loss: 2.8482, Test Loss: 2.4446, Accuracy: 0.0853\n",
      "Epoch 31/50, Train Loss: 2.7697, Test Loss: 2.4429, Accuracy: 0.0853\n",
      "Epoch 32/50, Train Loss: 2.7750, Test Loss: 2.4412, Accuracy: 0.0853\n",
      "Epoch 33/50, Train Loss: 2.8087, Test Loss: 2.4395, Accuracy: 0.0853\n",
      "Epoch 34/50, Train Loss: 2.8034, Test Loss: 2.4378, Accuracy: 0.0853\n",
      "Epoch 35/50, Train Loss: 2.8003, Test Loss: 2.4362, Accuracy: 0.0853\n",
      "Epoch 36/50, Train Loss: 2.8083, Test Loss: 2.4345, Accuracy: 0.0853\n",
      "Epoch 37/50, Train Loss: 2.7997, Test Loss: 2.4329, Accuracy: 0.0853\n",
      "Epoch 38/50, Train Loss: 2.7563, Test Loss: 2.4312, Accuracy: 0.0853\n",
      "Epoch 39/50, Train Loss: 2.7577, Test Loss: 2.4296, Accuracy: 0.0853\n",
      "Epoch 40/50, Train Loss: 2.7533, Test Loss: 2.4279, Accuracy: 0.0853\n",
      "Epoch 41/50, Train Loss: 2.8333, Test Loss: 2.4263, Accuracy: 0.0853\n",
      "Epoch 42/50, Train Loss: 2.7590, Test Loss: 2.4246, Accuracy: 0.0853\n",
      "Epoch 43/50, Train Loss: 2.7832, Test Loss: 2.4230, Accuracy: 0.0853\n",
      "Epoch 44/50, Train Loss: 2.7520, Test Loss: 2.4214, Accuracy: 0.0853\n",
      "Epoch 45/50, Train Loss: 2.7522, Test Loss: 2.4197, Accuracy: 0.0853\n",
      "Epoch 46/50, Train Loss: 2.8145, Test Loss: 2.4181, Accuracy: 0.0853\n",
      "Epoch 47/50, Train Loss: 2.7374, Test Loss: 2.4165, Accuracy: 0.0853\n",
      "Epoch 48/50, Train Loss: 2.7718, Test Loss: 2.4149, Accuracy: 0.0853\n",
      "Epoch 49/50, Train Loss: 2.7761, Test Loss: 2.4132, Accuracy: 0.0853\n",
      "Epoch 50/50, Train Loss: 2.8096, Test Loss: 2.4116, Accuracy: 0.0853\n",
      "Running experiment with params: {'batch_size': 32, 'learning_rate': 0.0001, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 2.7719, Test Loss: 2.4110, Accuracy: 0.0853\n",
      "Epoch 2/50, Train Loss: 2.7346, Test Loss: 2.4104, Accuracy: 0.0853\n",
      "Epoch 3/50, Train Loss: 2.7340, Test Loss: 2.4098, Accuracy: 0.0853\n",
      "Epoch 4/50, Train Loss: 2.7642, Test Loss: 2.4091, Accuracy: 0.0853\n",
      "Epoch 5/50, Train Loss: 2.7272, Test Loss: 2.4083, Accuracy: 0.0853\n",
      "Epoch 6/50, Train Loss: 2.7317, Test Loss: 2.4076, Accuracy: 0.0853\n",
      "Epoch 7/50, Train Loss: 2.7366, Test Loss: 2.4067, Accuracy: 0.0853\n",
      "Epoch 8/50, Train Loss: 2.8054, Test Loss: 2.4059, Accuracy: 0.0853\n",
      "Epoch 9/50, Train Loss: 2.7282, Test Loss: 2.4050, Accuracy: 0.0853\n",
      "Epoch 10/50, Train Loss: 2.7608, Test Loss: 2.4040, Accuracy: 0.0853\n",
      "Epoch 11/50, Train Loss: 2.7234, Test Loss: 2.4030, Accuracy: 0.0853\n",
      "Epoch 12/50, Train Loss: 2.7601, Test Loss: 2.4019, Accuracy: 0.0853\n",
      "Epoch 13/50, Train Loss: 2.7192, Test Loss: 2.4007, Accuracy: 0.0853\n",
      "Epoch 14/50, Train Loss: 2.7546, Test Loss: 2.3995, Accuracy: 0.0853\n",
      "Epoch 15/50, Train Loss: 2.7182, Test Loss: 2.3982, Accuracy: 0.0853\n",
      "Epoch 16/50, Train Loss: 2.7178, Test Loss: 2.3968, Accuracy: 0.0853\n",
      "Epoch 17/50, Train Loss: 2.7199, Test Loss: 2.3953, Accuracy: 0.0853\n",
      "Epoch 18/50, Train Loss: 2.7141, Test Loss: 2.3938, Accuracy: 0.0853\n",
      "Epoch 19/50, Train Loss: 2.7859, Test Loss: 2.3922, Accuracy: 0.0853\n",
      "Epoch 20/50, Train Loss: 2.7172, Test Loss: 2.3904, Accuracy: 0.0853\n",
      "Epoch 21/50, Train Loss: 2.7376, Test Loss: 2.3887, Accuracy: 0.0853\n",
      "Epoch 22/50, Train Loss: 2.7038, Test Loss: 2.3868, Accuracy: 0.0853\n",
      "Epoch 23/50, Train Loss: 2.7441, Test Loss: 2.3849, Accuracy: 0.0853\n",
      "Epoch 24/50, Train Loss: 2.7424, Test Loss: 2.3829, Accuracy: 0.0853\n",
      "Epoch 25/50, Train Loss: 2.7043, Test Loss: 2.3810, Accuracy: 0.0853\n",
      "Epoch 26/50, Train Loss: 2.6935, Test Loss: 2.3789, Accuracy: 0.0853\n",
      "Epoch 27/50, Train Loss: 2.6994, Test Loss: 2.3769, Accuracy: 0.0853\n",
      "Epoch 28/50, Train Loss: 2.7317, Test Loss: 2.3749, Accuracy: 0.0853\n",
      "Epoch 29/50, Train Loss: 2.7300, Test Loss: 2.3728, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 2.6936, Test Loss: 2.3708, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 2.6863, Test Loss: 2.3687, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 2.7193, Test Loss: 2.3667, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 2.6753, Test Loss: 2.3647, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 2.7922, Test Loss: 2.3627, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 2.6826, Test Loss: 2.3607, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 2.6737, Test Loss: 2.3587, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 2.6747, Test Loss: 2.3567, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 2.6765, Test Loss: 2.3547, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 2.6659, Test Loss: 2.3528, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 2.6707, Test Loss: 2.3508, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 2.6993, Test Loss: 2.3489, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 2.6628, Test Loss: 2.3470, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 2.6963, Test Loss: 2.3451, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 2.6567, Test Loss: 2.3432, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 2.6975, Test Loss: 2.3414, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 2.6936, Test Loss: 2.3395, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 2.6432, Test Loss: 2.3377, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 2.6511, Test Loss: 2.3358, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 2.6953, Test Loss: 2.3340, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 2.6393, Test Loss: 2.3323, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 64, 'learning_rate': 0.1, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 2.7372, Test Loss: 2.9778, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 3.4287, Test Loss: 4.4496, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 4.7781, Test Loss: 5.9061, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 5.8080, Test Loss: 7.2957, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 6.8951, Test Loss: 8.6164, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 7.7307, Test Loss: 9.8689, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 8.3074, Test Loss: 11.0533, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 9.5449, Test Loss: 12.1674, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 10.4702, Test Loss: 13.2060, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 11.1734, Test Loss: 14.1652, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 12.3364, Test Loss: 15.0428, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 12.1910, Test Loss: 15.8426, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 13.0558, Test Loss: 16.5738, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 13.8355, Test Loss: 17.2603, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 14.6602, Test Loss: 17.9542, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 15.2688, Test Loss: 18.7646, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 15.3651, Test Loss: 19.7740, Accuracy: 0.0426\n",
      "Epoch 18/50, Train Loss: 16.2956, Test Loss: 20.9005, Accuracy: 0.0426\n",
      "Epoch 19/50, Train Loss: 16.5872, Test Loss: 21.9982, Accuracy: 0.0426\n",
      "Epoch 20/50, Train Loss: 18.1682, Test Loss: 22.9783, Accuracy: 0.0426\n",
      "Epoch 21/50, Train Loss: 19.6324, Test Loss: 23.8083, Accuracy: 0.0426\n",
      "Epoch 22/50, Train Loss: 20.2886, Test Loss: 24.4807, Accuracy: 0.0426\n",
      "Epoch 23/50, Train Loss: 19.5997, Test Loss: 24.9990, Accuracy: 0.0426\n",
      "Epoch 24/50, Train Loss: 20.6349, Test Loss: 25.3777, Accuracy: 0.0426\n",
      "Epoch 25/50, Train Loss: 19.8084, Test Loss: 25.6476, Accuracy: 0.0426\n",
      "Epoch 26/50, Train Loss: 21.2669, Test Loss: 25.8690, Accuracy: 0.0504\n",
      "Epoch 27/50, Train Loss: 20.9155, Test Loss: 26.1074, Accuracy: 0.0504\n",
      "Epoch 28/50, Train Loss: 21.4409, Test Loss: 26.2942, Accuracy: 0.1047\n",
      "Epoch 29/50, Train Loss: 21.1639, Test Loss: 26.2224, Accuracy: 0.1047\n",
      "Epoch 30/50, Train Loss: 20.3399, Test Loss: 26.0021, Accuracy: 0.0504\n",
      "Epoch 31/50, Train Loss: 20.8983, Test Loss: 26.0346, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 21.7367, Test Loss: 26.3094, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 21.6947, Test Loss: 26.6535, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 21.3621, Test Loss: 26.9517, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 21.3744, Test Loss: 27.1443, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 21.2249, Test Loss: 27.2066, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 22.3992, Test Loss: 27.1406, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 21.1412, Test Loss: 26.9513, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 21.1133, Test Loss: 26.6532, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 20.8164, Test Loss: 26.2834, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 20.4226, Test Loss: 25.9314, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 20.3422, Test Loss: 25.8836, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 21.1387, Test Loss: 26.3534, Accuracy: 0.1047\n",
      "Epoch 44/50, Train Loss: 21.7439, Test Loss: 26.5190, Accuracy: 0.1047\n",
      "Epoch 45/50, Train Loss: 23.2880, Test Loss: 25.9175, Accuracy: 0.1047\n",
      "Epoch 46/50, Train Loss: 21.2181, Test Loss: 25.5902, Accuracy: 0.0504\n",
      "Epoch 47/50, Train Loss: 20.2651, Test Loss: 25.7278, Accuracy: 0.0504\n",
      "Epoch 48/50, Train Loss: 21.4544, Test Loss: 25.8735, Accuracy: 0.0504\n",
      "Epoch 49/50, Train Loss: 21.5955, Test Loss: 25.9690, Accuracy: 0.0504\n",
      "Epoch 50/50, Train Loss: 22.8261, Test Loss: 26.0929, Accuracy: 0.0504\n",
      "Running experiment with params: {'batch_size': 64, 'learning_rate': 0.1, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 21.2890, Test Loss: 26.7020, Accuracy: 0.0504\n",
      "Epoch 2/50, Train Loss: 23.9864, Test Loss: 27.1944, Accuracy: 0.0504\n",
      "Epoch 3/50, Train Loss: 25.0363, Test Loss: 27.4848, Accuracy: 0.0504\n",
      "Epoch 4/50, Train Loss: 24.2551, Test Loss: 27.6773, Accuracy: 0.0504\n",
      "Epoch 5/50, Train Loss: 22.3592, Test Loss: 27.8346, Accuracy: 0.0504\n",
      "Epoch 6/50, Train Loss: 22.5126, Test Loss: 27.9750, Accuracy: 0.0504\n",
      "Epoch 7/50, Train Loss: 24.7476, Test Loss: 28.1103, Accuracy: 0.0504\n",
      "Epoch 8/50, Train Loss: 22.5612, Test Loss: 28.2465, Accuracy: 0.0504\n",
      "Epoch 9/50, Train Loss: 22.5138, Test Loss: 28.3929, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 24.6750, Test Loss: 28.5541, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 25.8236, Test Loss: 28.7289, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 22.7253, Test Loss: 28.9127, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 23.9158, Test Loss: 29.1038, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 27.3151, Test Loss: 29.3088, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 25.2515, Test Loss: 29.5605, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 24.3750, Test Loss: 29.9134, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 24.6999, Test Loss: 30.3548, Accuracy: 0.1047\n",
      "Epoch 18/50, Train Loss: 23.9237, Test Loss: 30.7114, Accuracy: 0.1047\n",
      "Epoch 19/50, Train Loss: 25.2653, Test Loss: 30.8386, Accuracy: 0.1047\n",
      "Epoch 20/50, Train Loss: 26.4678, Test Loss: 30.8755, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 25.3760, Test Loss: 31.0537, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 24.4583, Test Loss: 31.3468, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 25.9324, Test Loss: 31.6596, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 26.1965, Test Loss: 31.9546, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 27.6811, Test Loss: 32.2224, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 25.5486, Test Loss: 32.4615, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 26.8957, Test Loss: 32.6721, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 27.0882, Test Loss: 32.8562, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 27.2055, Test Loss: 33.0152, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 26.0399, Test Loss: 33.1525, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 28.6050, Test Loss: 33.2748, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 26.1905, Test Loss: 33.3912, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 27.4520, Test Loss: 33.5180, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 26.2754, Test Loss: 33.6985, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 27.7050, Test Loss: 34.0068, Accuracy: 0.1047\n",
      "Epoch 36/50, Train Loss: 29.3040, Test Loss: 34.4286, Accuracy: 0.1047\n",
      "Epoch 37/50, Train Loss: 29.6251, Test Loss: 34.7156, Accuracy: 0.1047\n",
      "Epoch 38/50, Train Loss: 28.4320, Test Loss: 34.7029, Accuracy: 0.1047\n",
      "Epoch 39/50, Train Loss: 28.3492, Test Loss: 34.6253, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 27.0481, Test Loss: 34.7525, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 28.5389, Test Loss: 34.9986, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 30.1569, Test Loss: 35.2544, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 30.3810, Test Loss: 35.4835, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 29.2438, Test Loss: 35.6768, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 32.1388, Test Loss: 35.8349, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 29.5716, Test Loss: 35.9615, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 28.4098, Test Loss: 36.0640, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 31.1997, Test Loss: 36.1493, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 31.1860, Test Loss: 36.2242, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 28.5331, Test Loss: 36.2934, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 64, 'learning_rate': 0.01, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 28.5589, Test Loss: 36.3103, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 31.3569, Test Loss: 36.3267, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 32.7388, Test Loss: 36.3422, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 29.9716, Test Loss: 36.3568, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 30.0290, Test Loss: 36.3706, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 31.4623, Test Loss: 36.3835, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 28.6618, Test Loss: 36.3955, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 30.1546, Test Loss: 36.4069, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 30.0570, Test Loss: 36.4175, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 30.0574, Test Loss: 36.4276, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 28.6428, Test Loss: 36.4371, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 30.0611, Test Loss: 36.4463, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 28.7342, Test Loss: 36.4551, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 30.0558, Test Loss: 36.4635, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 30.0362, Test Loss: 36.4716, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 30.0790, Test Loss: 36.4794, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 30.0667, Test Loss: 36.4871, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 30.0197, Test Loss: 36.4946, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 30.0322, Test Loss: 36.5019, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 31.4663, Test Loss: 36.5091, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 30.0431, Test Loss: 36.5162, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 28.6446, Test Loss: 36.5230, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 31.5342, Test Loss: 36.5298, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 30.0305, Test Loss: 36.5362, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 28.6813, Test Loss: 36.5424, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 28.7232, Test Loss: 36.5484, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 30.0411, Test Loss: 36.5542, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 30.0713, Test Loss: 36.5597, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 30.1137, Test Loss: 36.5648, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 30.0140, Test Loss: 36.5695, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 31.4897, Test Loss: 36.5738, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 28.6438, Test Loss: 36.5777, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 30.0174, Test Loss: 36.5813, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 31.4157, Test Loss: 36.5845, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 30.0047, Test Loss: 36.5872, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 30.0020, Test Loss: 36.5895, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 30.0174, Test Loss: 36.5915, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 30.0305, Test Loss: 36.5931, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 30.0429, Test Loss: 36.5943, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 30.0532, Test Loss: 36.5951, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 30.0350, Test Loss: 36.5956, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 29.9749, Test Loss: 36.5957, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 30.0255, Test Loss: 36.5956, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 32.7555, Test Loss: 36.5953, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 29.9726, Test Loss: 36.5948, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 30.0199, Test Loss: 36.5942, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 29.9642, Test Loss: 36.5935, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 31.3627, Test Loss: 36.5929, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 29.9720, Test Loss: 36.5924, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 29.9690, Test Loss: 36.5918, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 64, 'learning_rate': 0.01, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 29.9731, Test Loss: 36.6084, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 31.3675, Test Loss: 36.6248, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 32.7840, Test Loss: 36.6407, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 31.3869, Test Loss: 36.6562, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 28.6347, Test Loss: 36.6712, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 30.0501, Test Loss: 36.6857, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 30.0331, Test Loss: 36.6998, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 30.0594, Test Loss: 36.7135, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 28.7182, Test Loss: 36.7267, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 30.0796, Test Loss: 36.7393, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 28.6959, Test Loss: 36.7516, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 28.7189, Test Loss: 36.7633, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 30.1280, Test Loss: 36.7748, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 31.5178, Test Loss: 36.7857, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 30.1452, Test Loss: 36.7963, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 28.7578, Test Loss: 36.8065, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 28.7491, Test Loss: 36.8163, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 31.5373, Test Loss: 36.8258, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 28.7831, Test Loss: 36.8349, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 31.5909, Test Loss: 36.8437, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 31.6044, Test Loss: 36.8522, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 30.1614, Test Loss: 36.8603, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 28.7718, Test Loss: 36.8681, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 28.7711, Test Loss: 36.8757, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 31.6021, Test Loss: 36.8831, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 31.5831, Test Loss: 36.8903, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 33.0122, Test Loss: 36.8972, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 31.6022, Test Loss: 36.9039, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 28.8170, Test Loss: 36.9105, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 30.2368, Test Loss: 36.9168, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 28.8272, Test Loss: 36.9229, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 31.6308, Test Loss: 36.9289, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 31.6373, Test Loss: 36.9347, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 30.2332, Test Loss: 36.9403, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 30.2259, Test Loss: 36.9458, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 28.8354, Test Loss: 36.9513, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 30.2290, Test Loss: 36.9567, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 28.8383, Test Loss: 36.9620, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 31.6667, Test Loss: 36.9673, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 30.2626, Test Loss: 36.9725, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 30.2678, Test Loss: 36.9776, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 28.8381, Test Loss: 36.9827, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 30.2587, Test Loss: 36.9879, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 31.6627, Test Loss: 36.9930, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 30.2576, Test Loss: 36.9981, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 28.8683, Test Loss: 37.0032, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 31.6909, Test Loss: 37.0084, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 30.2997, Test Loss: 37.0135, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 31.6744, Test Loss: 37.0186, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 31.6895, Test Loss: 37.0237, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 64, 'learning_rate': 0.001, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 30.2905, Test Loss: 37.0253, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 30.2784, Test Loss: 37.0269, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 28.8842, Test Loss: 37.0284, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 30.2743, Test Loss: 37.0300, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 28.8806, Test Loss: 37.0314, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 30.2788, Test Loss: 37.0329, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 30.2888, Test Loss: 37.0343, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 30.2858, Test Loss: 37.0357, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 31.6963, Test Loss: 37.0370, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 30.2876, Test Loss: 37.0383, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 31.7040, Test Loss: 37.0396, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 30.2700, Test Loss: 37.0409, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 28.8968, Test Loss: 37.0421, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 30.3105, Test Loss: 37.0433, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 31.7027, Test Loss: 37.0444, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 30.3159, Test Loss: 37.0455, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 30.2959, Test Loss: 37.0466, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 28.8977, Test Loss: 37.0476, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 31.7140, Test Loss: 37.0487, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 30.3159, Test Loss: 37.0497, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 28.8812, Test Loss: 37.0506, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 30.3000, Test Loss: 37.0515, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 30.3085, Test Loss: 37.0524, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 28.9032, Test Loss: 37.0533, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 30.3188, Test Loss: 37.0541, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 28.8869, Test Loss: 37.0549, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 33.1159, Test Loss: 37.0557, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 28.9059, Test Loss: 37.0564, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 28.8995, Test Loss: 37.0570, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 31.7008, Test Loss: 37.0577, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 30.3143, Test Loss: 37.0583, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 30.3079, Test Loss: 37.0589, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 30.2984, Test Loss: 37.0594, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 30.3077, Test Loss: 37.0599, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 30.3057, Test Loss: 37.0604, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 28.9023, Test Loss: 37.0608, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 28.8983, Test Loss: 37.0611, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 33.1211, Test Loss: 37.0615, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 28.8943, Test Loss: 37.0618, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 31.7107, Test Loss: 37.0620, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 31.7287, Test Loss: 37.0623, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 28.9102, Test Loss: 37.0624, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 31.7110, Test Loss: 37.0626, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 31.7245, Test Loss: 37.0627, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 30.3207, Test Loss: 37.0628, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 31.7205, Test Loss: 37.0628, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 31.7113, Test Loss: 37.0628, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 28.8905, Test Loss: 37.0627, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 28.9142, Test Loss: 37.0626, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 28.8967, Test Loss: 37.0625, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 64, 'learning_rate': 0.001, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 33.1287, Test Loss: 37.0640, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 30.3087, Test Loss: 37.0656, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 31.7414, Test Loss: 37.0671, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 33.1264, Test Loss: 37.0686, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 31.7339, Test Loss: 37.0700, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 30.3124, Test Loss: 37.0713, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 30.3211, Test Loss: 37.0726, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 31.7513, Test Loss: 37.0738, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 30.3230, Test Loss: 37.0750, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 30.3249, Test Loss: 37.0761, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 30.3160, Test Loss: 37.0771, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 33.1386, Test Loss: 37.0781, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 28.9211, Test Loss: 37.0791, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 30.3128, Test Loss: 37.0799, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 31.7551, Test Loss: 37.0807, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 34.5715, Test Loss: 37.0814, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 30.3237, Test Loss: 37.0821, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 30.3279, Test Loss: 37.0826, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 30.3159, Test Loss: 37.0831, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 33.1386, Test Loss: 37.0836, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 31.7187, Test Loss: 37.0839, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 31.7347, Test Loss: 37.0841, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 30.3516, Test Loss: 37.0843, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 28.9202, Test Loss: 37.0844, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 31.7477, Test Loss: 37.0844, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 30.3315, Test Loss: 37.0844, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 31.7214, Test Loss: 37.0842, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 30.3403, Test Loss: 37.0840, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 33.1602, Test Loss: 37.0836, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 30.3422, Test Loss: 37.0832, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 28.9222, Test Loss: 37.0827, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 31.7370, Test Loss: 37.0820, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 30.3294, Test Loss: 37.0813, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 30.3511, Test Loss: 37.0805, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 30.3275, Test Loss: 37.0796, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 30.3122, Test Loss: 37.0786, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 30.3282, Test Loss: 37.0776, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 31.7553, Test Loss: 37.0764, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 30.3086, Test Loss: 37.0751, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 28.9273, Test Loss: 37.0738, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 30.3162, Test Loss: 37.0723, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 30.3311, Test Loss: 37.0707, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 31.7036, Test Loss: 37.0690, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 34.5253, Test Loss: 37.0672, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 30.3019, Test Loss: 37.0653, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 34.5371, Test Loss: 37.0633, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 28.9017, Test Loss: 37.0611, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 28.8857, Test Loss: 37.0588, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 28.8760, Test Loss: 37.0565, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 31.7112, Test Loss: 37.0540, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 64, 'learning_rate': 0.0001, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 30.2898, Test Loss: 37.0539, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 28.8845, Test Loss: 37.0538, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 28.8930, Test Loss: 37.0537, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 30.3021, Test Loss: 37.0534, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 30.3030, Test Loss: 37.0531, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 30.3078, Test Loss: 37.0527, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 31.6958, Test Loss: 37.0522, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 30.2882, Test Loss: 37.0515, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 30.2814, Test Loss: 37.0509, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 28.8940, Test Loss: 37.0502, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 28.8875, Test Loss: 37.0495, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 31.6981, Test Loss: 37.0487, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 33.1168, Test Loss: 37.0480, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 31.7025, Test Loss: 37.0473, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 30.3096, Test Loss: 37.0466, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 30.3019, Test Loss: 37.0458, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 31.6808, Test Loss: 37.0451, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 33.1172, Test Loss: 37.0443, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 28.8811, Test Loss: 37.0436, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 30.2810, Test Loss: 37.0429, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 31.6927, Test Loss: 37.0421, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 33.1128, Test Loss: 37.0414, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 31.7009, Test Loss: 37.0406, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 30.2963, Test Loss: 37.0399, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 28.8833, Test Loss: 37.0392, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 33.0744, Test Loss: 37.0384, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 28.9018, Test Loss: 37.0377, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 31.7170, Test Loss: 37.0369, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 31.7099, Test Loss: 37.0362, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 28.8554, Test Loss: 37.0354, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 30.2783, Test Loss: 37.0346, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 28.8738, Test Loss: 37.0338, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 33.1053, Test Loss: 37.0331, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 28.8776, Test Loss: 37.0323, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 30.2822, Test Loss: 37.0315, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 31.6778, Test Loss: 37.0306, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 30.2860, Test Loss: 37.0298, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 31.6761, Test Loss: 37.0290, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 28.8602, Test Loss: 37.0281, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 28.8530, Test Loss: 37.0273, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 30.2636, Test Loss: 37.0264, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 30.2954, Test Loss: 37.0256, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 28.8575, Test Loss: 37.0247, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 33.0940, Test Loss: 37.0238, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 31.6777, Test Loss: 37.0229, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 33.0666, Test Loss: 37.0220, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 31.6616, Test Loss: 37.0211, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 30.2763, Test Loss: 37.0201, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 31.6930, Test Loss: 37.0192, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 30.2424, Test Loss: 37.0182, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 64, 'learning_rate': 0.0001, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 30.2802, Test Loss: 37.0178, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 28.8442, Test Loss: 37.0173, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 28.8504, Test Loss: 37.0168, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 30.2528, Test Loss: 37.0162, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 30.2591, Test Loss: 37.0156, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 33.0388, Test Loss: 37.0148, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 28.8416, Test Loss: 37.0139, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 28.8593, Test Loss: 37.0129, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 31.6781, Test Loss: 37.0117, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 28.8580, Test Loss: 37.0103, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 30.2464, Test Loss: 37.0088, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 28.8495, Test Loss: 37.0072, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 31.6663, Test Loss: 37.0055, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 31.6520, Test Loss: 37.0038, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 30.2477, Test Loss: 37.0020, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 31.6621, Test Loss: 37.0002, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 31.6680, Test Loss: 36.9984, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 30.2371, Test Loss: 36.9965, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 30.2300, Test Loss: 36.9947, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 31.6370, Test Loss: 36.9929, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 31.6356, Test Loss: 36.9911, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 31.6278, Test Loss: 36.9892, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 31.6264, Test Loss: 36.9874, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 28.8400, Test Loss: 36.9856, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 31.6361, Test Loss: 36.9838, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 30.2391, Test Loss: 36.9820, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 30.2370, Test Loss: 36.9803, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 30.2302, Test Loss: 36.9785, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 30.2288, Test Loss: 36.9767, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 31.6622, Test Loss: 36.9749, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 30.2379, Test Loss: 36.9731, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 28.8216, Test Loss: 36.9712, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 28.8143, Test Loss: 36.9694, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 31.6170, Test Loss: 36.9676, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 30.2194, Test Loss: 36.9658, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 28.8364, Test Loss: 36.9641, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 31.6244, Test Loss: 36.9623, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 28.8284, Test Loss: 36.9605, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 28.8252, Test Loss: 36.9587, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 30.2381, Test Loss: 36.9570, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 30.1918, Test Loss: 36.9552, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 28.8231, Test Loss: 36.9534, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 28.8082, Test Loss: 36.9516, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 28.8065, Test Loss: 36.9498, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 31.6000, Test Loss: 36.9481, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 30.2115, Test Loss: 36.9463, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 30.1896, Test Loss: 36.9445, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 30.2010, Test Loss: 36.9428, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 31.6145, Test Loss: 36.9410, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 28.7853, Test Loss: 36.9393, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 128, 'learning_rate': 0.1, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 29.8228, Test Loss: 43.3769, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 31.8551, Test Loss: 42.5146, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 28.6290, Test Loss: 41.6589, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 30.6455, Test Loss: 40.8089, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 27.5224, Test Loss: 39.9645, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 24.4776, Test Loss: 39.1260, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 31.2082, Test Loss: 38.2933, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 30.5476, Test Loss: 37.4661, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 25.2504, Test Loss: 36.6443, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 29.1960, Test Loss: 35.8282, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 21.9855, Test Loss: 35.0180, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 21.4887, Test Loss: 34.2131, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 25.2029, Test Loss: 33.4138, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 24.5802, Test Loss: 32.6192, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 20.0569, Test Loss: 31.8290, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 21.5275, Test Loss: 31.0436, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 20.9929, Test Loss: 30.2637, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 22.3221, Test Loss: 29.4891, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 18.1411, Test Loss: 28.7194, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 19.4696, Test Loss: 27.9553, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 20.6129, Test Loss: 27.1966, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 16.7872, Test Loss: 26.4430, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 17.9455, Test Loss: 25.6949, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 17.4876, Test Loss: 24.9518, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 16.9340, Test Loss: 24.2138, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 17.8956, Test Loss: 23.4810, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 17.3584, Test Loss: 22.7535, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 16.8023, Test Loss: 22.0310, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 15.0174, Test Loss: 21.3144, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 14.5333, Test Loss: 20.6033, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 12.8361, Test Loss: 19.8973, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 14.7055, Test Loss: 19.1966, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 12.0153, Test Loss: 18.5017, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 12.6725, Test Loss: 17.8118, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 11.1702, Test Loss: 17.1269, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 11.7531, Test Loss: 16.4472, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 12.2243, Test Loss: 15.7716, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 9.9814, Test Loss: 15.0993, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 9.5370, Test Loss: 14.4308, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 9.9480, Test Loss: 13.7657, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 9.5146, Test Loss: 13.1044, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 8.4004, Test Loss: 12.4472, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 9.2944, Test Loss: 11.7935, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 8.1998, Test Loss: 11.1439, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 7.8335, Test Loss: 10.4995, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 7.3757, Test Loss: 9.8605, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 6.4234, Test Loss: 9.2274, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 6.0249, Test Loss: 8.6001, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 5.6580, Test Loss: 7.9790, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 6.4728, Test Loss: 7.3640, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 128, 'learning_rate': 0.1, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 5.2885, Test Loss: 6.8257, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 4.9482, Test Loss: 6.2919, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 4.8859, Test Loss: 5.7623, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 4.7533, Test Loss: 5.2366, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 3.8873, Test Loss: 4.7143, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 3.5386, Test Loss: 4.1959, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 3.1634, Test Loss: 3.6815, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 2.7210, Test Loss: 3.1719, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 2.6028, Test Loss: 2.6685, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 2.1904, Test Loss: 2.1833, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 1.8440, Test Loss: 1.7899, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 1.7656, Test Loss: 1.7844, Accuracy: 0.0853\n",
      "Epoch 13/50, Train Loss: 2.2191, Test Loss: 2.5021, Accuracy: 0.0853\n",
      "Epoch 14/50, Train Loss: 3.3269, Test Loss: 3.6302, Accuracy: 0.0853\n",
      "Epoch 15/50, Train Loss: 4.6824, Test Loss: 4.8128, Accuracy: 0.0853\n",
      "Epoch 16/50, Train Loss: 6.0834, Test Loss: 5.9471, Accuracy: 0.0853\n",
      "Epoch 17/50, Train Loss: 7.1856, Test Loss: 7.0127, Accuracy: 0.0853\n",
      "Epoch 18/50, Train Loss: 8.1473, Test Loss: 8.0053, Accuracy: 0.0853\n",
      "Epoch 19/50, Train Loss: 9.2440, Test Loss: 8.9259, Accuracy: 0.0853\n",
      "Epoch 20/50, Train Loss: 10.4475, Test Loss: 9.7780, Accuracy: 0.0853\n",
      "Epoch 21/50, Train Loss: 10.8488, Test Loss: 10.5631, Accuracy: 0.0853\n",
      "Epoch 22/50, Train Loss: 12.1181, Test Loss: 11.2805, Accuracy: 0.0853\n",
      "Epoch 23/50, Train Loss: 12.7214, Test Loss: 11.9309, Accuracy: 0.0736\n",
      "Epoch 24/50, Train Loss: 13.3717, Test Loss: 12.5174, Accuracy: 0.0736\n",
      "Epoch 25/50, Train Loss: 13.7332, Test Loss: 13.0394, Accuracy: 0.0736\n",
      "Epoch 26/50, Train Loss: 13.5912, Test Loss: 13.4943, Accuracy: 0.0736\n",
      "Epoch 27/50, Train Loss: 14.9945, Test Loss: 13.8827, Accuracy: 0.0736\n",
      "Epoch 28/50, Train Loss: 15.0113, Test Loss: 14.2060, Accuracy: 0.0736\n",
      "Epoch 29/50, Train Loss: 15.9018, Test Loss: 14.4646, Accuracy: 0.0736\n",
      "Epoch 30/50, Train Loss: 15.7120, Test Loss: 14.6590, Accuracy: 0.0736\n",
      "Epoch 31/50, Train Loss: 16.1041, Test Loss: 14.7917, Accuracy: 0.0736\n",
      "Epoch 32/50, Train Loss: 15.5054, Test Loss: 14.8659, Accuracy: 0.0736\n",
      "Epoch 33/50, Train Loss: 15.7579, Test Loss: 14.8854, Accuracy: 0.0736\n",
      "Epoch 34/50, Train Loss: 15.8871, Test Loss: 14.8537, Accuracy: 0.0736\n",
      "Epoch 35/50, Train Loss: 15.8968, Test Loss: 14.7760, Accuracy: 0.0736\n",
      "Epoch 36/50, Train Loss: 15.4079, Test Loss: 14.6607, Accuracy: 0.0736\n",
      "Epoch 37/50, Train Loss: 15.5700, Test Loss: 14.5316, Accuracy: 0.0736\n",
      "Epoch 38/50, Train Loss: 14.7156, Test Loss: 14.4583, Accuracy: 0.0736\n",
      "Epoch 39/50, Train Loss: 15.2107, Test Loss: 14.5915, Accuracy: 0.0736\n",
      "Epoch 40/50, Train Loss: 15.6598, Test Loss: 15.0468, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 15.8374, Test Loss: 15.7162, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 18.5304, Test Loss: 16.4177, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 16.9880, Test Loss: 17.0480, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 19.5578, Test Loss: 17.5750, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 18.0321, Test Loss: 17.9925, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 17.9996, Test Loss: 18.2981, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 18.9404, Test Loss: 18.4964, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 20.4835, Test Loss: 18.5887, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 18.4625, Test Loss: 18.5747, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 18.4129, Test Loss: 18.4560, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 128, 'learning_rate': 0.01, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 18.2152, Test Loss: 18.4621, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 19.5186, Test Loss: 18.4602, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 18.6959, Test Loss: 18.4366, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 18.6821, Test Loss: 18.3740, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 19.4906, Test Loss: 18.2683, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 19.9238, Test Loss: 18.1345, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 17.7634, Test Loss: 17.9863, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 20.0235, Test Loss: 17.8314, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 19.1691, Test Loss: 17.6729, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 19.3318, Test Loss: 17.5123, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 18.4694, Test Loss: 17.3507, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 18.1787, Test Loss: 17.1887, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 19.5606, Test Loss: 17.0273, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 21.2136, Test Loss: 16.8666, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 18.3210, Test Loss: 16.7071, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 18.7786, Test Loss: 16.5495, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 18.9862, Test Loss: 16.3944, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 17.0607, Test Loss: 16.2426, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 17.3694, Test Loss: 16.0953, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 18.7173, Test Loss: 15.9536, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 17.7086, Test Loss: 15.8185, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 19.8802, Test Loss: 15.6914, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 16.6292, Test Loss: 15.5735, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 18.8142, Test Loss: 15.4662, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 16.5149, Test Loss: 15.3707, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 16.9119, Test Loss: 15.2879, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 16.8308, Test Loss: 15.2186, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 17.7043, Test Loss: 15.1630, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 19.5435, Test Loss: 15.1207, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 18.1864, Test Loss: 15.0911, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 16.8287, Test Loss: 15.0730, Accuracy: 0.0853\n",
      "Epoch 32/50, Train Loss: 17.7348, Test Loss: 15.0652, Accuracy: 0.0853\n",
      "Epoch 33/50, Train Loss: 16.8923, Test Loss: 15.0660, Accuracy: 0.0853\n",
      "Epoch 34/50, Train Loss: 17.7854, Test Loss: 15.0740, Accuracy: 0.0853\n",
      "Epoch 35/50, Train Loss: 16.5188, Test Loss: 15.0875, Accuracy: 0.0853\n",
      "Epoch 36/50, Train Loss: 18.8227, Test Loss: 15.1050, Accuracy: 0.0853\n",
      "Epoch 37/50, Train Loss: 18.4924, Test Loss: 15.1254, Accuracy: 0.0853\n",
      "Epoch 38/50, Train Loss: 18.0723, Test Loss: 15.1474, Accuracy: 0.0853\n",
      "Epoch 39/50, Train Loss: 18.0503, Test Loss: 15.1702, Accuracy: 0.0853\n",
      "Epoch 40/50, Train Loss: 18.1133, Test Loss: 15.1931, Accuracy: 0.0853\n",
      "Epoch 41/50, Train Loss: 17.2618, Test Loss: 15.2152, Accuracy: 0.0853\n",
      "Epoch 42/50, Train Loss: 17.4015, Test Loss: 15.2361, Accuracy: 0.0853\n",
      "Epoch 43/50, Train Loss: 19.2162, Test Loss: 15.2552, Accuracy: 0.0853\n",
      "Epoch 44/50, Train Loss: 18.3554, Test Loss: 15.2722, Accuracy: 0.0853\n",
      "Epoch 45/50, Train Loss: 18.4543, Test Loss: 15.2868, Accuracy: 0.0853\n",
      "Epoch 46/50, Train Loss: 17.0632, Test Loss: 15.2986, Accuracy: 0.0853\n",
      "Epoch 47/50, Train Loss: 17.8905, Test Loss: 15.3075, Accuracy: 0.0853\n",
      "Epoch 48/50, Train Loss: 17.9156, Test Loss: 15.3133, Accuracy: 0.0736\n",
      "Epoch 49/50, Train Loss: 19.8675, Test Loss: 15.3157, Accuracy: 0.0736\n",
      "Epoch 50/50, Train Loss: 18.5256, Test Loss: 15.3147, Accuracy: 0.0736\n",
      "Running experiment with params: {'batch_size': 128, 'learning_rate': 0.01, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 17.6465, Test Loss: 15.3754, Accuracy: 0.0736\n",
      "Epoch 2/50, Train Loss: 18.6220, Test Loss: 15.4199, Accuracy: 0.0736\n",
      "Epoch 3/50, Train Loss: 18.7640, Test Loss: 15.4435, Accuracy: 0.0736\n",
      "Epoch 4/50, Train Loss: 18.7648, Test Loss: 15.4628, Accuracy: 0.0736\n",
      "Epoch 5/50, Train Loss: 19.5168, Test Loss: 15.4819, Accuracy: 0.0736\n",
      "Epoch 6/50, Train Loss: 20.4997, Test Loss: 15.4989, Accuracy: 0.0736\n",
      "Epoch 7/50, Train Loss: 18.8162, Test Loss: 15.5095, Accuracy: 0.0736\n",
      "Epoch 8/50, Train Loss: 18.9299, Test Loss: 15.5086, Accuracy: 0.0736\n",
      "Epoch 9/50, Train Loss: 18.6902, Test Loss: 15.4906, Accuracy: 0.0736\n",
      "Epoch 10/50, Train Loss: 19.0950, Test Loss: 15.4511, Accuracy: 0.0736\n",
      "Epoch 11/50, Train Loss: 18.7364, Test Loss: 15.3877, Accuracy: 0.0736\n",
      "Epoch 12/50, Train Loss: 19.3986, Test Loss: 15.3002, Accuracy: 0.0736\n",
      "Epoch 13/50, Train Loss: 18.6683, Test Loss: 15.1919, Accuracy: 0.0736\n",
      "Epoch 14/50, Train Loss: 18.8802, Test Loss: 15.0669, Accuracy: 0.0736\n",
      "Epoch 15/50, Train Loss: 17.5537, Test Loss: 14.9293, Accuracy: 0.0736\n",
      "Epoch 16/50, Train Loss: 17.8115, Test Loss: 14.7828, Accuracy: 0.0736\n",
      "Epoch 17/50, Train Loss: 18.0518, Test Loss: 14.6299, Accuracy: 0.0736\n",
      "Epoch 18/50, Train Loss: 18.0859, Test Loss: 14.4727, Accuracy: 0.0736\n",
      "Epoch 19/50, Train Loss: 17.0421, Test Loss: 14.3123, Accuracy: 0.0736\n",
      "Epoch 20/50, Train Loss: 17.1237, Test Loss: 14.1497, Accuracy: 0.0736\n",
      "Epoch 21/50, Train Loss: 18.5438, Test Loss: 13.9854, Accuracy: 0.0736\n",
      "Epoch 22/50, Train Loss: 19.1505, Test Loss: 13.8200, Accuracy: 0.0736\n",
      "Epoch 23/50, Train Loss: 15.7862, Test Loss: 13.6539, Accuracy: 0.0736\n",
      "Epoch 24/50, Train Loss: 16.3522, Test Loss: 13.4875, Accuracy: 0.0736\n",
      "Epoch 25/50, Train Loss: 17.0250, Test Loss: 13.3213, Accuracy: 0.0736\n",
      "Epoch 26/50, Train Loss: 16.0859, Test Loss: 13.1561, Accuracy: 0.0736\n",
      "Epoch 27/50, Train Loss: 15.3813, Test Loss: 12.9928, Accuracy: 0.0736\n",
      "Epoch 28/50, Train Loss: 16.5420, Test Loss: 12.8326, Accuracy: 0.0736\n",
      "Epoch 29/50, Train Loss: 16.8242, Test Loss: 12.6769, Accuracy: 0.0736\n",
      "Epoch 30/50, Train Loss: 15.1934, Test Loss: 12.5271, Accuracy: 0.0736\n",
      "Epoch 31/50, Train Loss: 15.9562, Test Loss: 12.3852, Accuracy: 0.0736\n",
      "Epoch 32/50, Train Loss: 15.7974, Test Loss: 12.2529, Accuracy: 0.0736\n",
      "Epoch 33/50, Train Loss: 17.1296, Test Loss: 12.1322, Accuracy: 0.0736\n",
      "Epoch 34/50, Train Loss: 15.3855, Test Loss: 12.0247, Accuracy: 0.0736\n",
      "Epoch 35/50, Train Loss: 15.2499, Test Loss: 11.9318, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 14.9648, Test Loss: 11.8541, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 13.4068, Test Loss: 11.7915, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 13.5908, Test Loss: 11.7433, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 13.5942, Test Loss: 11.7080, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 13.5143, Test Loss: 11.6835, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 13.1977, Test Loss: 11.6673, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 14.4373, Test Loss: 11.6570, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 16.6249, Test Loss: 11.6501, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 13.3641, Test Loss: 11.6440, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 14.3167, Test Loss: 11.6370, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 13.9740, Test Loss: 11.6272, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 14.8171, Test Loss: 11.6133, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 14.0113, Test Loss: 11.5936, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 13.8946, Test Loss: 11.5670, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 15.1414, Test Loss: 11.5323, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 128, 'learning_rate': 0.001, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 15.5721, Test Loss: 11.5248, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 15.0426, Test Loss: 11.5171, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 14.9507, Test Loss: 11.5090, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 14.6162, Test Loss: 11.5005, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 13.4297, Test Loss: 11.4916, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 13.6772, Test Loss: 11.4824, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 12.9365, Test Loss: 11.4729, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 14.3180, Test Loss: 11.4632, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 13.7045, Test Loss: 11.4533, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 12.9644, Test Loss: 11.4432, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 14.0134, Test Loss: 11.4329, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 14.1395, Test Loss: 11.4223, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 13.2242, Test Loss: 11.4116, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 13.8576, Test Loss: 11.4007, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 14.7906, Test Loss: 11.3897, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 15.4233, Test Loss: 11.3785, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 13.8388, Test Loss: 11.3671, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 13.5696, Test Loss: 11.3556, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 15.1854, Test Loss: 11.3439, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 15.2499, Test Loss: 11.3322, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 14.5097, Test Loss: 11.3202, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 13.8464, Test Loss: 11.3082, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 13.9761, Test Loss: 11.2960, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 14.8726, Test Loss: 11.2838, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 13.1379, Test Loss: 11.2714, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 12.8197, Test Loss: 11.2589, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 14.3790, Test Loss: 11.2464, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 13.2583, Test Loss: 11.2338, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 14.2984, Test Loss: 11.2211, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 13.7280, Test Loss: 11.2083, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 13.8819, Test Loss: 11.1955, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 14.1201, Test Loss: 11.1827, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 13.6539, Test Loss: 11.1697, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 12.9327, Test Loss: 11.1567, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 15.8682, Test Loss: 11.1437, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 14.7425, Test Loss: 11.1306, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 13.8677, Test Loss: 11.1175, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 13.7948, Test Loss: 11.1042, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 12.7092, Test Loss: 11.0910, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 13.3040, Test Loss: 11.0777, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 14.6970, Test Loss: 11.0644, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 13.8035, Test Loss: 11.0510, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 14.2194, Test Loss: 11.0376, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 14.8756, Test Loss: 11.0242, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 12.6104, Test Loss: 11.0108, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 15.3694, Test Loss: 10.9973, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 13.6644, Test Loss: 10.9838, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 14.4262, Test Loss: 10.9702, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 14.1631, Test Loss: 10.9567, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 14.9926, Test Loss: 10.9430, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 128, 'learning_rate': 0.001, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 12.6356, Test Loss: 10.9345, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 14.3073, Test Loss: 10.9260, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 13.9021, Test Loss: 10.9174, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 14.2456, Test Loss: 10.9086, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 13.4974, Test Loss: 10.8998, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 13.1397, Test Loss: 10.8908, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 14.9107, Test Loss: 10.8817, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 14.7196, Test Loss: 10.8724, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 13.5945, Test Loss: 10.8630, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 13.7798, Test Loss: 10.8534, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 14.0331, Test Loss: 10.8437, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 14.4195, Test Loss: 10.8339, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 13.3668, Test Loss: 10.8238, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 13.5235, Test Loss: 10.8136, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 13.3384, Test Loss: 10.8031, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 13.4734, Test Loss: 10.7925, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 13.6636, Test Loss: 10.7816, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 13.4617, Test Loss: 10.7706, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 12.9024, Test Loss: 10.7593, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 12.8449, Test Loss: 10.7478, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 13.6701, Test Loss: 10.7360, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 13.7223, Test Loss: 10.7240, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 12.5844, Test Loss: 10.7118, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 13.6544, Test Loss: 10.6993, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 12.2176, Test Loss: 10.6866, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 13.5830, Test Loss: 10.6737, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 13.6230, Test Loss: 10.6606, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 12.4777, Test Loss: 10.6474, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 13.8251, Test Loss: 10.6340, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 12.5040, Test Loss: 10.6205, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 12.4934, Test Loss: 10.6068, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 13.0856, Test Loss: 10.5930, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 14.1919, Test Loss: 10.5791, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 13.7613, Test Loss: 10.5652, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 13.3018, Test Loss: 10.5512, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 14.2048, Test Loss: 10.5372, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 14.3591, Test Loss: 10.5232, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 12.8236, Test Loss: 10.5092, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 14.1797, Test Loss: 10.4951, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 14.5668, Test Loss: 10.4811, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 12.9429, Test Loss: 10.4670, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 15.6212, Test Loss: 10.4530, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 15.1937, Test Loss: 10.4390, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 12.9421, Test Loss: 10.4250, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 13.2366, Test Loss: 10.4111, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 13.8005, Test Loss: 10.3971, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 14.0176, Test Loss: 10.3832, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 13.8382, Test Loss: 10.3694, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 14.6872, Test Loss: 10.3556, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 14.4507, Test Loss: 10.3419, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 128, 'learning_rate': 0.0001, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 12.1939, Test Loss: 10.3407, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 13.7626, Test Loss: 10.3396, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 12.4191, Test Loss: 10.3385, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 14.3165, Test Loss: 10.3374, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 13.0021, Test Loss: 10.3363, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 12.7311, Test Loss: 10.3352, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 13.5312, Test Loss: 10.3340, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 14.3942, Test Loss: 10.3329, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 13.1571, Test Loss: 10.3318, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 14.0437, Test Loss: 10.3306, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 13.7684, Test Loss: 10.3295, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 14.6028, Test Loss: 10.3284, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 12.9913, Test Loss: 10.3272, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 12.4094, Test Loss: 10.3261, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 12.8461, Test Loss: 10.3249, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 12.8592, Test Loss: 10.3238, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 12.4498, Test Loss: 10.3226, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 13.9606, Test Loss: 10.3214, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 13.1018, Test Loss: 10.3203, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 12.4025, Test Loss: 10.3191, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 13.1562, Test Loss: 10.3179, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 12.5770, Test Loss: 10.3168, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 12.2607, Test Loss: 10.3156, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 13.1707, Test Loss: 10.3144, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 13.1524, Test Loss: 10.3132, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 12.8964, Test Loss: 10.3120, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 14.4821, Test Loss: 10.3108, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 13.8172, Test Loss: 10.3096, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 13.7698, Test Loss: 10.3084, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 13.1649, Test Loss: 10.3072, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 13.0713, Test Loss: 10.3060, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 13.7766, Test Loss: 10.3048, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 14.2444, Test Loss: 10.3036, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 13.5817, Test Loss: 10.3024, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 14.2540, Test Loss: 10.3012, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 12.4355, Test Loss: 10.3000, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 14.4219, Test Loss: 10.2988, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 12.7018, Test Loss: 10.2976, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 13.3356, Test Loss: 10.2963, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 13.3768, Test Loss: 10.2951, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 12.6568, Test Loss: 10.2939, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 13.7109, Test Loss: 10.2927, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 12.6543, Test Loss: 10.2915, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 13.2846, Test Loss: 10.2902, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 15.0484, Test Loss: 10.2890, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 14.6556, Test Loss: 10.2878, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 12.1955, Test Loss: 10.2866, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 13.0700, Test Loss: 10.2853, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 12.1936, Test Loss: 10.2841, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 13.0725, Test Loss: 10.2829, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 128, 'learning_rate': 0.0001, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 13.7481, Test Loss: 10.2818, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 12.8662, Test Loss: 10.2807, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 12.2780, Test Loss: 10.2796, Accuracy: 0.4612\n",
      "Epoch 4/50, Train Loss: 13.5204, Test Loss: 10.2785, Accuracy: 0.4612\n",
      "Epoch 5/50, Train Loss: 12.7322, Test Loss: 10.2774, Accuracy: 0.4612\n",
      "Epoch 6/50, Train Loss: 13.5140, Test Loss: 10.2763, Accuracy: 0.4612\n",
      "Epoch 7/50, Train Loss: 13.7225, Test Loss: 10.2752, Accuracy: 0.4612\n",
      "Epoch 8/50, Train Loss: 13.0916, Test Loss: 10.2741, Accuracy: 0.4612\n",
      "Epoch 9/50, Train Loss: 13.4942, Test Loss: 10.2730, Accuracy: 0.4612\n",
      "Epoch 10/50, Train Loss: 13.3021, Test Loss: 10.2718, Accuracy: 0.4612\n",
      "Epoch 11/50, Train Loss: 13.3617, Test Loss: 10.2707, Accuracy: 0.4612\n",
      "Epoch 12/50, Train Loss: 12.9095, Test Loss: 10.2696, Accuracy: 0.4612\n",
      "Epoch 13/50, Train Loss: 11.9567, Test Loss: 10.2685, Accuracy: 0.4612\n",
      "Epoch 14/50, Train Loss: 12.6830, Test Loss: 10.2674, Accuracy: 0.4612\n",
      "Epoch 15/50, Train Loss: 12.6723, Test Loss: 10.2663, Accuracy: 0.4612\n",
      "Epoch 16/50, Train Loss: 12.8135, Test Loss: 10.2651, Accuracy: 0.4612\n",
      "Epoch 17/50, Train Loss: 13.1124, Test Loss: 10.2640, Accuracy: 0.4612\n",
      "Epoch 18/50, Train Loss: 14.4448, Test Loss: 10.2629, Accuracy: 0.4612\n",
      "Epoch 19/50, Train Loss: 13.7864, Test Loss: 10.2617, Accuracy: 0.4612\n",
      "Epoch 20/50, Train Loss: 12.4460, Test Loss: 10.2606, Accuracy: 0.4612\n",
      "Epoch 21/50, Train Loss: 13.4848, Test Loss: 10.2595, Accuracy: 0.4612\n",
      "Epoch 22/50, Train Loss: 13.5046, Test Loss: 10.2583, Accuracy: 0.4612\n",
      "Epoch 23/50, Train Loss: 12.8073, Test Loss: 10.2572, Accuracy: 0.4612\n",
      "Epoch 24/50, Train Loss: 13.7816, Test Loss: 10.2561, Accuracy: 0.4612\n",
      "Epoch 25/50, Train Loss: 14.1312, Test Loss: 10.2549, Accuracy: 0.4612\n",
      "Epoch 26/50, Train Loss: 13.3336, Test Loss: 10.2538, Accuracy: 0.4612\n",
      "Epoch 27/50, Train Loss: 12.8909, Test Loss: 10.2526, Accuracy: 0.4612\n",
      "Epoch 28/50, Train Loss: 12.4742, Test Loss: 10.2515, Accuracy: 0.4612\n",
      "Epoch 29/50, Train Loss: 12.0303, Test Loss: 10.2503, Accuracy: 0.4612\n",
      "Epoch 30/50, Train Loss: 12.8881, Test Loss: 10.2492, Accuracy: 0.4612\n",
      "Epoch 31/50, Train Loss: 13.5068, Test Loss: 10.2480, Accuracy: 0.4612\n",
      "Epoch 32/50, Train Loss: 12.0276, Test Loss: 10.2469, Accuracy: 0.4612\n",
      "Epoch 33/50, Train Loss: 13.9656, Test Loss: 10.2457, Accuracy: 0.4612\n",
      "Epoch 34/50, Train Loss: 13.0425, Test Loss: 10.2446, Accuracy: 0.4612\n",
      "Epoch 35/50, Train Loss: 11.9787, Test Loss: 10.2434, Accuracy: 0.4612\n",
      "Epoch 36/50, Train Loss: 13.6830, Test Loss: 10.2422, Accuracy: 0.4612\n",
      "Epoch 37/50, Train Loss: 14.5695, Test Loss: 10.2411, Accuracy: 0.4612\n",
      "Epoch 38/50, Train Loss: 13.5035, Test Loss: 10.2399, Accuracy: 0.4612\n",
      "Epoch 39/50, Train Loss: 12.6060, Test Loss: 10.2387, Accuracy: 0.4612\n",
      "Epoch 40/50, Train Loss: 13.4555, Test Loss: 10.2376, Accuracy: 0.4612\n",
      "Epoch 41/50, Train Loss: 12.7911, Test Loss: 10.2364, Accuracy: 0.4612\n",
      "Epoch 42/50, Train Loss: 13.5055, Test Loss: 10.2352, Accuracy: 0.4612\n",
      "Epoch 43/50, Train Loss: 13.0419, Test Loss: 10.2341, Accuracy: 0.4612\n",
      "Epoch 44/50, Train Loss: 12.9872, Test Loss: 10.2329, Accuracy: 0.4612\n",
      "Epoch 45/50, Train Loss: 12.7874, Test Loss: 10.2317, Accuracy: 0.4612\n",
      "Epoch 46/50, Train Loss: 12.6453, Test Loss: 10.2305, Accuracy: 0.4612\n",
      "Epoch 47/50, Train Loss: 13.6726, Test Loss: 10.2294, Accuracy: 0.4612\n",
      "Epoch 48/50, Train Loss: 13.7043, Test Loss: 10.2282, Accuracy: 0.4612\n",
      "Epoch 49/50, Train Loss: 12.7726, Test Loss: 10.2270, Accuracy: 0.4612\n",
      "Epoch 50/50, Train Loss: 13.5386, Test Loss: 10.2258, Accuracy: 0.4612\n",
      "Running experiment with params: {'batch_size': 256, 'learning_rate': 0.1, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 13.5403, Test Loss: 8.9430, Accuracy: 0.4612\n",
      "Epoch 2/50, Train Loss: 13.7841, Test Loss: 8.4792, Accuracy: 0.4612\n",
      "Epoch 3/50, Train Loss: 11.2190, Test Loss: 8.2499, Accuracy: 0.0853\n",
      "Epoch 4/50, Train Loss: 10.8259, Test Loss: 8.2293, Accuracy: 0.0853\n",
      "Epoch 5/50, Train Loss: 13.7637, Test Loss: 8.3245, Accuracy: 0.0853\n",
      "Epoch 6/50, Train Loss: 15.9952, Test Loss: 8.4545, Accuracy: 0.0853\n",
      "Epoch 7/50, Train Loss: 11.7330, Test Loss: 8.5721, Accuracy: 0.0853\n",
      "Epoch 8/50, Train Loss: 12.2672, Test Loss: 8.6513, Accuracy: 0.0853\n",
      "Epoch 9/50, Train Loss: 12.2125, Test Loss: 8.6734, Accuracy: 0.0853\n",
      "Epoch 10/50, Train Loss: 13.3377, Test Loss: 8.6249, Accuracy: 0.0853\n",
      "Epoch 11/50, Train Loss: 14.6760, Test Loss: 8.4947, Accuracy: 0.0853\n",
      "Epoch 12/50, Train Loss: 14.3537, Test Loss: 8.2744, Accuracy: 0.0853\n",
      "Epoch 13/50, Train Loss: 12.5020, Test Loss: 7.9623, Accuracy: 0.0853\n",
      "Epoch 14/50, Train Loss: 12.0087, Test Loss: 7.5628, Accuracy: 0.0853\n",
      "Epoch 15/50, Train Loss: 13.0214, Test Loss: 7.0883, Accuracy: 0.0853\n",
      "Epoch 16/50, Train Loss: 14.0923, Test Loss: 6.5601, Accuracy: 0.0853\n",
      "Epoch 17/50, Train Loss: 12.7532, Test Loss: 6.0194, Accuracy: 0.0853\n",
      "Epoch 18/50, Train Loss: 11.5572, Test Loss: 5.5616, Accuracy: 0.0853\n",
      "Epoch 19/50, Train Loss: 9.8065, Test Loss: 5.3649, Accuracy: 0.1822\n",
      "Epoch 20/50, Train Loss: 10.6203, Test Loss: 5.5508, Accuracy: 0.1822\n",
      "Epoch 21/50, Train Loss: 10.3313, Test Loss: 6.0070, Accuracy: 0.1822\n",
      "Epoch 22/50, Train Loss: 11.3254, Test Loss: 6.5687, Accuracy: 0.1822\n",
      "Epoch 23/50, Train Loss: 11.7778, Test Loss: 7.1561, Accuracy: 0.1822\n",
      "Epoch 24/50, Train Loss: 13.2957, Test Loss: 7.7428, Accuracy: 0.1822\n",
      "Epoch 25/50, Train Loss: 12.9553, Test Loss: 8.3215, Accuracy: 0.1822\n",
      "Epoch 26/50, Train Loss: 13.7487, Test Loss: 8.8902, Accuracy: 0.1822\n",
      "Epoch 27/50, Train Loss: 15.2402, Test Loss: 9.4485, Accuracy: 0.1822\n",
      "Epoch 28/50, Train Loss: 14.3032, Test Loss: 9.9967, Accuracy: 0.1822\n",
      "Epoch 29/50, Train Loss: 14.8293, Test Loss: 10.5352, Accuracy: 0.1822\n",
      "Epoch 30/50, Train Loss: 15.2262, Test Loss: 11.0648, Accuracy: 0.1822\n",
      "Epoch 31/50, Train Loss: 16.6714, Test Loss: 11.5858, Accuracy: 0.1822\n",
      "Epoch 32/50, Train Loss: 15.9984, Test Loss: 12.0986, Accuracy: 0.1822\n",
      "Epoch 33/50, Train Loss: 17.0247, Test Loss: 12.6035, Accuracy: 0.1822\n",
      "Epoch 34/50, Train Loss: 16.6510, Test Loss: 13.1007, Accuracy: 0.1822\n",
      "Epoch 35/50, Train Loss: 18.7970, Test Loss: 13.5903, Accuracy: 0.1822\n",
      "Epoch 36/50, Train Loss: 18.9920, Test Loss: 14.0725, Accuracy: 0.1822\n",
      "Epoch 37/50, Train Loss: 18.0082, Test Loss: 14.5475, Accuracy: 0.1822\n",
      "Epoch 38/50, Train Loss: 17.9279, Test Loss: 15.0155, Accuracy: 0.1822\n",
      "Epoch 39/50, Train Loss: 19.0089, Test Loss: 15.4766, Accuracy: 0.1822\n",
      "Epoch 40/50, Train Loss: 20.2635, Test Loss: 15.9310, Accuracy: 0.1822\n",
      "Epoch 41/50, Train Loss: 19.3268, Test Loss: 16.3789, Accuracy: 0.1822\n",
      "Epoch 42/50, Train Loss: 21.1445, Test Loss: 16.8205, Accuracy: 0.1822\n",
      "Epoch 43/50, Train Loss: 19.7512, Test Loss: 17.2558, Accuracy: 0.1822\n",
      "Epoch 44/50, Train Loss: 22.7047, Test Loss: 17.6848, Accuracy: 0.1822\n",
      "Epoch 45/50, Train Loss: 22.3997, Test Loss: 18.1074, Accuracy: 0.1822\n",
      "Epoch 46/50, Train Loss: 22.5657, Test Loss: 18.5233, Accuracy: 0.1822\n",
      "Epoch 47/50, Train Loss: 22.6181, Test Loss: 18.9327, Accuracy: 0.1822\n",
      "Epoch 48/50, Train Loss: 23.9214, Test Loss: 19.3359, Accuracy: 0.1822\n",
      "Epoch 49/50, Train Loss: 23.9328, Test Loss: 19.7330, Accuracy: 0.1822\n",
      "Epoch 50/50, Train Loss: 23.7807, Test Loss: 20.1242, Accuracy: 0.1822\n",
      "Running experiment with params: {'batch_size': 256, 'learning_rate': 0.1, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 25.1822, Test Loss: 20.5831, Accuracy: 0.1822\n",
      "Epoch 2/50, Train Loss: 24.6954, Test Loss: 21.0391, Accuracy: 0.1822\n",
      "Epoch 3/50, Train Loss: 24.3953, Test Loss: 21.4919, Accuracy: 0.1822\n",
      "Epoch 4/50, Train Loss: 25.8041, Test Loss: 21.9410, Accuracy: 0.1822\n",
      "Epoch 5/50, Train Loss: 25.7206, Test Loss: 22.3859, Accuracy: 0.1822\n",
      "Epoch 6/50, Train Loss: 27.2928, Test Loss: 22.8263, Accuracy: 0.1822\n",
      "Epoch 7/50, Train Loss: 28.7480, Test Loss: 23.2620, Accuracy: 0.1822\n",
      "Epoch 8/50, Train Loss: 27.2184, Test Loss: 23.6927, Accuracy: 0.1822\n",
      "Epoch 9/50, Train Loss: 26.5099, Test Loss: 24.1183, Accuracy: 0.1822\n",
      "Epoch 10/50, Train Loss: 29.7283, Test Loss: 24.5386, Accuracy: 0.1822\n",
      "Epoch 11/50, Train Loss: 27.7389, Test Loss: 24.9539, Accuracy: 0.1822\n",
      "Epoch 12/50, Train Loss: 31.0477, Test Loss: 25.3639, Accuracy: 0.1822\n",
      "Epoch 13/50, Train Loss: 28.1315, Test Loss: 25.7685, Accuracy: 0.1822\n",
      "Epoch 14/50, Train Loss: 28.5656, Test Loss: 26.1675, Accuracy: 0.1822\n",
      "Epoch 15/50, Train Loss: 30.4489, Test Loss: 26.5612, Accuracy: 0.1822\n",
      "Epoch 16/50, Train Loss: 30.9229, Test Loss: 26.9495, Accuracy: 0.1822\n",
      "Epoch 17/50, Train Loss: 31.2715, Test Loss: 27.3324, Accuracy: 0.1822\n",
      "Epoch 18/50, Train Loss: 33.8236, Test Loss: 27.7099, Accuracy: 0.1822\n",
      "Epoch 19/50, Train Loss: 33.6150, Test Loss: 28.0821, Accuracy: 0.1822\n",
      "Epoch 20/50, Train Loss: 30.1353, Test Loss: 28.4489, Accuracy: 0.1822\n",
      "Epoch 21/50, Train Loss: 28.3109, Test Loss: 28.8104, Accuracy: 0.1822\n",
      "Epoch 22/50, Train Loss: 32.3024, Test Loss: 29.1667, Accuracy: 0.1822\n",
      "Epoch 23/50, Train Loss: 33.5164, Test Loss: 29.5176, Accuracy: 0.1822\n",
      "Epoch 24/50, Train Loss: 31.2183, Test Loss: 29.8630, Accuracy: 0.1822\n",
      "Epoch 25/50, Train Loss: 35.6621, Test Loss: 30.2030, Accuracy: 0.1822\n",
      "Epoch 26/50, Train Loss: 33.3128, Test Loss: 30.5376, Accuracy: 0.1822\n",
      "Epoch 27/50, Train Loss: 37.1028, Test Loss: 30.8667, Accuracy: 0.1822\n",
      "Epoch 28/50, Train Loss: 31.9244, Test Loss: 31.1898, Accuracy: 0.1822\n",
      "Epoch 29/50, Train Loss: 37.5659, Test Loss: 31.5070, Accuracy: 0.1822\n",
      "Epoch 30/50, Train Loss: 31.4784, Test Loss: 31.8186, Accuracy: 0.1822\n",
      "Epoch 31/50, Train Loss: 37.7009, Test Loss: 32.1247, Accuracy: 0.1822\n",
      "Epoch 32/50, Train Loss: 39.0929, Test Loss: 32.4252, Accuracy: 0.1822\n",
      "Epoch 33/50, Train Loss: 35.2736, Test Loss: 32.7194, Accuracy: 0.1822\n",
      "Epoch 34/50, Train Loss: 36.7341, Test Loss: 33.0076, Accuracy: 0.1822\n",
      "Epoch 35/50, Train Loss: 41.4208, Test Loss: 33.2898, Accuracy: 0.1822\n",
      "Epoch 36/50, Train Loss: 39.4542, Test Loss: 33.5658, Accuracy: 0.1822\n",
      "Epoch 37/50, Train Loss: 40.2407, Test Loss: 33.8355, Accuracy: 0.1822\n",
      "Epoch 38/50, Train Loss: 34.1048, Test Loss: 34.0988, Accuracy: 0.1822\n",
      "Epoch 39/50, Train Loss: 36.6104, Test Loss: 34.3560, Accuracy: 0.1822\n",
      "Epoch 40/50, Train Loss: 40.3089, Test Loss: 34.6069, Accuracy: 0.1822\n",
      "Epoch 41/50, Train Loss: 36.4433, Test Loss: 34.8514, Accuracy: 0.1822\n",
      "Epoch 42/50, Train Loss: 40.8510, Test Loss: 35.0895, Accuracy: 0.1822\n",
      "Epoch 43/50, Train Loss: 36.7929, Test Loss: 35.3212, Accuracy: 0.1822\n",
      "Epoch 44/50, Train Loss: 40.9970, Test Loss: 35.5467, Accuracy: 0.1822\n",
      "Epoch 45/50, Train Loss: 39.0923, Test Loss: 35.7653, Accuracy: 0.1822\n",
      "Epoch 46/50, Train Loss: 42.7193, Test Loss: 35.9772, Accuracy: 0.1822\n",
      "Epoch 47/50, Train Loss: 39.6934, Test Loss: 36.1822, Accuracy: 0.1822\n",
      "Epoch 48/50, Train Loss: 43.2292, Test Loss: 36.3806, Accuracy: 0.1822\n",
      "Epoch 49/50, Train Loss: 40.1301, Test Loss: 36.5720, Accuracy: 0.1822\n",
      "Epoch 50/50, Train Loss: 40.3305, Test Loss: 36.7566, Accuracy: 0.1822\n",
      "Running experiment with params: {'batch_size': 256, 'learning_rate': 0.01, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 40.0879, Test Loss: 36.7943, Accuracy: 0.1822\n",
      "Epoch 2/50, Train Loss: 44.4589, Test Loss: 36.8318, Accuracy: 0.1822\n",
      "Epoch 3/50, Train Loss: 41.0941, Test Loss: 36.8690, Accuracy: 0.1822\n",
      "Epoch 4/50, Train Loss: 39.6760, Test Loss: 36.9057, Accuracy: 0.1822\n",
      "Epoch 5/50, Train Loss: 42.6239, Test Loss: 36.9417, Accuracy: 0.1822\n",
      "Epoch 6/50, Train Loss: 38.9147, Test Loss: 36.9771, Accuracy: 0.1822\n",
      "Epoch 7/50, Train Loss: 40.6521, Test Loss: 37.0118, Accuracy: 0.1822\n",
      "Epoch 8/50, Train Loss: 42.8765, Test Loss: 37.0456, Accuracy: 0.1822\n",
      "Epoch 9/50, Train Loss: 40.7410, Test Loss: 37.0786, Accuracy: 0.1822\n",
      "Epoch 10/50, Train Loss: 36.7542, Test Loss: 37.1106, Accuracy: 0.1822\n",
      "Epoch 11/50, Train Loss: 44.0521, Test Loss: 37.1416, Accuracy: 0.1822\n",
      "Epoch 12/50, Train Loss: 42.8728, Test Loss: 37.1713, Accuracy: 0.1822\n",
      "Epoch 13/50, Train Loss: 43.0255, Test Loss: 37.1996, Accuracy: 0.1822\n",
      "Epoch 14/50, Train Loss: 42.7319, Test Loss: 37.2267, Accuracy: 0.1822\n",
      "Epoch 15/50, Train Loss: 43.5479, Test Loss: 37.2524, Accuracy: 0.1822\n",
      "Epoch 16/50, Train Loss: 40.2407, Test Loss: 37.2766, Accuracy: 0.1822\n",
      "Epoch 17/50, Train Loss: 42.6041, Test Loss: 37.2994, Accuracy: 0.1822\n",
      "Epoch 18/50, Train Loss: 40.8300, Test Loss: 37.3206, Accuracy: 0.1822\n",
      "Epoch 19/50, Train Loss: 43.0838, Test Loss: 37.3398, Accuracy: 0.1822\n",
      "Epoch 20/50, Train Loss: 41.2934, Test Loss: 37.3572, Accuracy: 0.1822\n",
      "Epoch 21/50, Train Loss: 44.5784, Test Loss: 37.3725, Accuracy: 0.1822\n",
      "Epoch 22/50, Train Loss: 43.0932, Test Loss: 37.3856, Accuracy: 0.1822\n",
      "Epoch 23/50, Train Loss: 39.4566, Test Loss: 37.3963, Accuracy: 0.1822\n",
      "Epoch 24/50, Train Loss: 42.9813, Test Loss: 37.4046, Accuracy: 0.1822\n",
      "Epoch 25/50, Train Loss: 41.1552, Test Loss: 37.4106, Accuracy: 0.1822\n",
      "Epoch 26/50, Train Loss: 43.0314, Test Loss: 37.4141, Accuracy: 0.1822\n",
      "Epoch 27/50, Train Loss: 38.8529, Test Loss: 37.4150, Accuracy: 0.1822\n",
      "Epoch 28/50, Train Loss: 43.3836, Test Loss: 37.4136, Accuracy: 0.1822\n",
      "Epoch 29/50, Train Loss: 38.9805, Test Loss: 37.4098, Accuracy: 0.1822\n",
      "Epoch 30/50, Train Loss: 42.1766, Test Loss: 37.4037, Accuracy: 0.1822\n",
      "Epoch 31/50, Train Loss: 39.7662, Test Loss: 37.3955, Accuracy: 0.1822\n",
      "Epoch 32/50, Train Loss: 40.9135, Test Loss: 37.3852, Accuracy: 0.1822\n",
      "Epoch 33/50, Train Loss: 39.5593, Test Loss: 37.3733, Accuracy: 0.1822\n",
      "Epoch 34/50, Train Loss: 45.3575, Test Loss: 37.3594, Accuracy: 0.1822\n",
      "Epoch 35/50, Train Loss: 47.2288, Test Loss: 37.3439, Accuracy: 0.1822\n",
      "Epoch 36/50, Train Loss: 41.8278, Test Loss: 37.3268, Accuracy: 0.1822\n",
      "Epoch 37/50, Train Loss: 38.7062, Test Loss: 37.3082, Accuracy: 0.1822\n",
      "Epoch 38/50, Train Loss: 41.3519, Test Loss: 37.2881, Accuracy: 0.1822\n",
      "Epoch 39/50, Train Loss: 42.8387, Test Loss: 37.2666, Accuracy: 0.1822\n",
      "Epoch 40/50, Train Loss: 43.7225, Test Loss: 37.2437, Accuracy: 0.1822\n",
      "Epoch 41/50, Train Loss: 43.4738, Test Loss: 37.2195, Accuracy: 0.1822\n",
      "Epoch 42/50, Train Loss: 41.4567, Test Loss: 37.1940, Accuracy: 0.1822\n",
      "Epoch 43/50, Train Loss: 43.3519, Test Loss: 37.1672, Accuracy: 0.1822\n",
      "Epoch 44/50, Train Loss: 45.3827, Test Loss: 37.1392, Accuracy: 0.1822\n",
      "Epoch 45/50, Train Loss: 40.9460, Test Loss: 37.1099, Accuracy: 0.1822\n",
      "Epoch 46/50, Train Loss: 43.3526, Test Loss: 37.0793, Accuracy: 0.1822\n",
      "Epoch 47/50, Train Loss: 44.7735, Test Loss: 37.0474, Accuracy: 0.1822\n",
      "Epoch 48/50, Train Loss: 45.0188, Test Loss: 37.0142, Accuracy: 0.1822\n",
      "Epoch 49/50, Train Loss: 42.5008, Test Loss: 36.9796, Accuracy: 0.1822\n",
      "Epoch 50/50, Train Loss: 38.3226, Test Loss: 36.9437, Accuracy: 0.1822\n",
      "Running experiment with params: {'batch_size': 256, 'learning_rate': 0.01, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 41.0653, Test Loss: 36.8861, Accuracy: 0.1822\n",
      "Epoch 2/50, Train Loss: 41.3016, Test Loss: 36.8276, Accuracy: 0.1822\n",
      "Epoch 3/50, Train Loss: 45.1003, Test Loss: 36.7678, Accuracy: 0.1822\n",
      "Epoch 4/50, Train Loss: 42.5938, Test Loss: 36.7062, Accuracy: 0.1822\n",
      "Epoch 5/50, Train Loss: 38.8834, Test Loss: 36.6430, Accuracy: 0.1822\n",
      "Epoch 6/50, Train Loss: 42.4901, Test Loss: 36.5781, Accuracy: 0.1822\n",
      "Epoch 7/50, Train Loss: 40.1330, Test Loss: 36.5116, Accuracy: 0.1822\n",
      "Epoch 8/50, Train Loss: 40.1068, Test Loss: 36.4436, Accuracy: 0.1822\n",
      "Epoch 9/50, Train Loss: 40.8758, Test Loss: 36.3742, Accuracy: 0.1822\n",
      "Epoch 10/50, Train Loss: 41.8720, Test Loss: 36.3037, Accuracy: 0.1822\n",
      "Epoch 11/50, Train Loss: 38.7947, Test Loss: 36.2322, Accuracy: 0.1822\n",
      "Epoch 12/50, Train Loss: 40.3096, Test Loss: 36.1597, Accuracy: 0.1822\n",
      "Epoch 13/50, Train Loss: 40.5784, Test Loss: 36.0863, Accuracy: 0.1822\n",
      "Epoch 14/50, Train Loss: 40.2649, Test Loss: 36.0123, Accuracy: 0.1822\n",
      "Epoch 15/50, Train Loss: 41.7315, Test Loss: 35.9376, Accuracy: 0.1822\n",
      "Epoch 16/50, Train Loss: 38.6613, Test Loss: 35.8623, Accuracy: 0.1822\n",
      "Epoch 17/50, Train Loss: 39.7226, Test Loss: 35.7864, Accuracy: 0.1822\n",
      "Epoch 18/50, Train Loss: 39.7799, Test Loss: 35.7101, Accuracy: 0.1822\n",
      "Epoch 19/50, Train Loss: 41.9070, Test Loss: 35.6333, Accuracy: 0.1822\n",
      "Epoch 20/50, Train Loss: 40.3130, Test Loss: 35.5562, Accuracy: 0.1822\n",
      "Epoch 21/50, Train Loss: 44.1592, Test Loss: 35.4788, Accuracy: 0.1822\n",
      "Epoch 22/50, Train Loss: 43.6522, Test Loss: 35.4010, Accuracy: 0.1822\n",
      "Epoch 23/50, Train Loss: 41.3905, Test Loss: 35.3230, Accuracy: 0.1822\n",
      "Epoch 24/50, Train Loss: 39.7529, Test Loss: 35.2447, Accuracy: 0.1822\n",
      "Epoch 25/50, Train Loss: 35.3120, Test Loss: 35.1663, Accuracy: 0.1822\n",
      "Epoch 26/50, Train Loss: 39.0062, Test Loss: 35.0876, Accuracy: 0.1822\n",
      "Epoch 27/50, Train Loss: 40.9031, Test Loss: 35.0088, Accuracy: 0.1822\n",
      "Epoch 28/50, Train Loss: 37.7147, Test Loss: 34.9298, Accuracy: 0.1822\n",
      "Epoch 29/50, Train Loss: 38.9676, Test Loss: 34.8506, Accuracy: 0.1822\n",
      "Epoch 30/50, Train Loss: 40.8757, Test Loss: 34.7712, Accuracy: 0.1822\n",
      "Epoch 31/50, Train Loss: 40.8036, Test Loss: 34.6917, Accuracy: 0.1822\n",
      "Epoch 32/50, Train Loss: 37.1405, Test Loss: 34.6121, Accuracy: 0.1822\n",
      "Epoch 33/50, Train Loss: 41.4844, Test Loss: 34.5323, Accuracy: 0.1822\n",
      "Epoch 34/50, Train Loss: 38.3538, Test Loss: 34.4525, Accuracy: 0.1822\n",
      "Epoch 35/50, Train Loss: 35.1360, Test Loss: 34.3726, Accuracy: 0.1822\n",
      "Epoch 36/50, Train Loss: 40.9770, Test Loss: 34.2926, Accuracy: 0.1822\n",
      "Epoch 37/50, Train Loss: 38.7064, Test Loss: 34.2126, Accuracy: 0.1822\n",
      "Epoch 38/50, Train Loss: 40.2451, Test Loss: 34.1326, Accuracy: 0.1822\n",
      "Epoch 39/50, Train Loss: 42.5336, Test Loss: 34.0527, Accuracy: 0.1822\n",
      "Epoch 40/50, Train Loss: 37.6280, Test Loss: 33.9728, Accuracy: 0.1822\n",
      "Epoch 41/50, Train Loss: 36.0636, Test Loss: 33.8929, Accuracy: 0.1822\n",
      "Epoch 42/50, Train Loss: 38.2013, Test Loss: 33.8132, Accuracy: 0.1822\n",
      "Epoch 43/50, Train Loss: 41.5472, Test Loss: 33.7337, Accuracy: 0.1822\n",
      "Epoch 44/50, Train Loss: 39.4173, Test Loss: 33.6543, Accuracy: 0.1822\n",
      "Epoch 45/50, Train Loss: 39.0157, Test Loss: 33.5751, Accuracy: 0.1822\n",
      "Epoch 46/50, Train Loss: 39.2719, Test Loss: 33.4962, Accuracy: 0.1822\n",
      "Epoch 47/50, Train Loss: 40.1032, Test Loss: 33.4176, Accuracy: 0.1822\n",
      "Epoch 48/50, Train Loss: 41.2560, Test Loss: 33.3393, Accuracy: 0.1822\n",
      "Epoch 49/50, Train Loss: 39.2613, Test Loss: 33.2615, Accuracy: 0.1822\n",
      "Epoch 50/50, Train Loss: 35.2807, Test Loss: 33.1842, Accuracy: 0.1822\n",
      "Running experiment with params: {'batch_size': 256, 'learning_rate': 0.001, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 37.1246, Test Loss: 33.1791, Accuracy: 0.1822\n",
      "Epoch 2/50, Train Loss: 37.6816, Test Loss: 33.1739, Accuracy: 0.1822\n",
      "Epoch 3/50, Train Loss: 39.2206, Test Loss: 33.1688, Accuracy: 0.1822\n",
      "Epoch 4/50, Train Loss: 37.3641, Test Loss: 33.1636, Accuracy: 0.1822\n",
      "Epoch 5/50, Train Loss: 38.9294, Test Loss: 33.1584, Accuracy: 0.1822\n",
      "Epoch 6/50, Train Loss: 35.7333, Test Loss: 33.1532, Accuracy: 0.1822\n",
      "Epoch 7/50, Train Loss: 38.8979, Test Loss: 33.1479, Accuracy: 0.1822\n",
      "Epoch 8/50, Train Loss: 41.4967, Test Loss: 33.1426, Accuracy: 0.1822\n",
      "Epoch 9/50, Train Loss: 33.3856, Test Loss: 33.1373, Accuracy: 0.1822\n",
      "Epoch 10/50, Train Loss: 41.0259, Test Loss: 33.1320, Accuracy: 0.1822\n",
      "Epoch 11/50, Train Loss: 36.3746, Test Loss: 33.1266, Accuracy: 0.1822\n",
      "Epoch 12/50, Train Loss: 38.9735, Test Loss: 33.1213, Accuracy: 0.1822\n",
      "Epoch 13/50, Train Loss: 41.0112, Test Loss: 33.1158, Accuracy: 0.1822\n",
      "Epoch 14/50, Train Loss: 37.0350, Test Loss: 33.1104, Accuracy: 0.1822\n",
      "Epoch 15/50, Train Loss: 37.1280, Test Loss: 33.1049, Accuracy: 0.1822\n",
      "Epoch 16/50, Train Loss: 35.2923, Test Loss: 33.0994, Accuracy: 0.1822\n",
      "Epoch 17/50, Train Loss: 39.9764, Test Loss: 33.0939, Accuracy: 0.1822\n",
      "Epoch 18/50, Train Loss: 37.2876, Test Loss: 33.0883, Accuracy: 0.1822\n",
      "Epoch 19/50, Train Loss: 33.4187, Test Loss: 33.0827, Accuracy: 0.1822\n",
      "Epoch 20/50, Train Loss: 38.8462, Test Loss: 33.0771, Accuracy: 0.1822\n",
      "Epoch 21/50, Train Loss: 41.7490, Test Loss: 33.0715, Accuracy: 0.1822\n",
      "Epoch 22/50, Train Loss: 41.4420, Test Loss: 33.0658, Accuracy: 0.1822\n",
      "Epoch 23/50, Train Loss: 31.2678, Test Loss: 33.0601, Accuracy: 0.1822\n",
      "Epoch 24/50, Train Loss: 41.7441, Test Loss: 33.0544, Accuracy: 0.1822\n",
      "Epoch 25/50, Train Loss: 37.5495, Test Loss: 33.0487, Accuracy: 0.1822\n",
      "Epoch 26/50, Train Loss: 37.6053, Test Loss: 33.0430, Accuracy: 0.1822\n",
      "Epoch 27/50, Train Loss: 36.6706, Test Loss: 33.0372, Accuracy: 0.1822\n",
      "Epoch 28/50, Train Loss: 37.5588, Test Loss: 33.0314, Accuracy: 0.1822\n",
      "Epoch 29/50, Train Loss: 35.5073, Test Loss: 33.0256, Accuracy: 0.1822\n",
      "Epoch 30/50, Train Loss: 35.3158, Test Loss: 33.0198, Accuracy: 0.1822\n",
      "Epoch 31/50, Train Loss: 35.9253, Test Loss: 33.0139, Accuracy: 0.1822\n",
      "Epoch 32/50, Train Loss: 34.4383, Test Loss: 33.0081, Accuracy: 0.1822\n",
      "Epoch 33/50, Train Loss: 37.2115, Test Loss: 33.0022, Accuracy: 0.1822\n",
      "Epoch 34/50, Train Loss: 41.6636, Test Loss: 32.9963, Accuracy: 0.1822\n",
      "Epoch 35/50, Train Loss: 34.7890, Test Loss: 32.9904, Accuracy: 0.1822\n",
      "Epoch 36/50, Train Loss: 35.8958, Test Loss: 32.9845, Accuracy: 0.1822\n",
      "Epoch 37/50, Train Loss: 36.6102, Test Loss: 32.9786, Accuracy: 0.1822\n",
      "Epoch 38/50, Train Loss: 37.4977, Test Loss: 32.9726, Accuracy: 0.1822\n",
      "Epoch 39/50, Train Loss: 39.5189, Test Loss: 32.9667, Accuracy: 0.1822\n",
      "Epoch 40/50, Train Loss: 35.5319, Test Loss: 32.9607, Accuracy: 0.1822\n",
      "Epoch 41/50, Train Loss: 37.5586, Test Loss: 32.9547, Accuracy: 0.1822\n",
      "Epoch 42/50, Train Loss: 41.1355, Test Loss: 32.9487, Accuracy: 0.1822\n",
      "Epoch 43/50, Train Loss: 37.6648, Test Loss: 32.9426, Accuracy: 0.1822\n",
      "Epoch 44/50, Train Loss: 35.6055, Test Loss: 32.9366, Accuracy: 0.1822\n",
      "Epoch 45/50, Train Loss: 39.2832, Test Loss: 32.9305, Accuracy: 0.1822\n",
      "Epoch 46/50, Train Loss: 41.4133, Test Loss: 32.9244, Accuracy: 0.1822\n",
      "Epoch 47/50, Train Loss: 40.6354, Test Loss: 32.9184, Accuracy: 0.1822\n",
      "Epoch 48/50, Train Loss: 33.0911, Test Loss: 32.9123, Accuracy: 0.1822\n",
      "Epoch 49/50, Train Loss: 39.1743, Test Loss: 32.9062, Accuracy: 0.1822\n",
      "Epoch 50/50, Train Loss: 32.9880, Test Loss: 32.9000, Accuracy: 0.1822\n",
      "Running experiment with params: {'batch_size': 256, 'learning_rate': 0.001, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 38.9556, Test Loss: 32.8952, Accuracy: 0.1822\n",
      "Epoch 2/50, Train Loss: 39.5218, Test Loss: 32.8903, Accuracy: 0.1822\n",
      "Epoch 3/50, Train Loss: 37.1227, Test Loss: 32.8855, Accuracy: 0.1822\n",
      "Epoch 4/50, Train Loss: 37.1179, Test Loss: 32.8806, Accuracy: 0.1822\n",
      "Epoch 5/50, Train Loss: 36.9952, Test Loss: 32.8757, Accuracy: 0.1822\n",
      "Epoch 6/50, Train Loss: 35.1804, Test Loss: 32.8708, Accuracy: 0.1822\n",
      "Epoch 7/50, Train Loss: 37.0895, Test Loss: 32.8659, Accuracy: 0.1822\n",
      "Epoch 8/50, Train Loss: 35.5299, Test Loss: 32.8610, Accuracy: 0.1822\n",
      "Epoch 9/50, Train Loss: 41.2565, Test Loss: 32.8560, Accuracy: 0.1822\n",
      "Epoch 10/50, Train Loss: 38.4500, Test Loss: 32.8511, Accuracy: 0.1822\n",
      "Epoch 11/50, Train Loss: 35.2318, Test Loss: 32.8461, Accuracy: 0.1822\n",
      "Epoch 12/50, Train Loss: 41.2343, Test Loss: 32.8411, Accuracy: 0.1822\n",
      "Epoch 13/50, Train Loss: 39.7713, Test Loss: 32.8360, Accuracy: 0.1822\n",
      "Epoch 14/50, Train Loss: 39.2635, Test Loss: 32.8309, Accuracy: 0.1822\n",
      "Epoch 15/50, Train Loss: 38.7778, Test Loss: 32.8258, Accuracy: 0.1822\n",
      "Epoch 16/50, Train Loss: 41.2258, Test Loss: 32.8207, Accuracy: 0.1822\n",
      "Epoch 17/50, Train Loss: 40.5364, Test Loss: 32.8155, Accuracy: 0.1822\n",
      "Epoch 18/50, Train Loss: 35.1987, Test Loss: 32.8103, Accuracy: 0.1822\n",
      "Epoch 19/50, Train Loss: 37.5503, Test Loss: 32.8050, Accuracy: 0.1822\n",
      "Epoch 20/50, Train Loss: 34.5040, Test Loss: 32.7998, Accuracy: 0.1822\n",
      "Epoch 21/50, Train Loss: 37.1915, Test Loss: 32.7944, Accuracy: 0.1822\n",
      "Epoch 22/50, Train Loss: 35.1154, Test Loss: 32.7891, Accuracy: 0.1822\n",
      "Epoch 23/50, Train Loss: 38.8708, Test Loss: 32.7837, Accuracy: 0.1822\n",
      "Epoch 24/50, Train Loss: 36.7354, Test Loss: 32.7782, Accuracy: 0.1822\n",
      "Epoch 25/50, Train Loss: 38.5657, Test Loss: 32.7728, Accuracy: 0.1822\n",
      "Epoch 26/50, Train Loss: 37.1614, Test Loss: 32.7673, Accuracy: 0.1822\n",
      "Epoch 27/50, Train Loss: 39.1946, Test Loss: 32.7617, Accuracy: 0.1822\n",
      "Epoch 28/50, Train Loss: 35.3777, Test Loss: 32.7562, Accuracy: 0.1822\n",
      "Epoch 29/50, Train Loss: 37.0668, Test Loss: 32.7506, Accuracy: 0.1822\n",
      "Epoch 30/50, Train Loss: 35.1504, Test Loss: 32.7450, Accuracy: 0.1822\n",
      "Epoch 31/50, Train Loss: 37.4724, Test Loss: 32.7394, Accuracy: 0.1822\n",
      "Epoch 32/50, Train Loss: 40.1476, Test Loss: 32.7338, Accuracy: 0.1822\n",
      "Epoch 33/50, Train Loss: 35.0633, Test Loss: 32.7282, Accuracy: 0.1822\n",
      "Epoch 34/50, Train Loss: 37.1751, Test Loss: 32.7226, Accuracy: 0.1822\n",
      "Epoch 35/50, Train Loss: 40.6993, Test Loss: 32.7169, Accuracy: 0.1822\n",
      "Epoch 36/50, Train Loss: 34.4041, Test Loss: 32.7112, Accuracy: 0.1822\n",
      "Epoch 37/50, Train Loss: 38.7679, Test Loss: 32.7056, Accuracy: 0.1822\n",
      "Epoch 38/50, Train Loss: 36.7140, Test Loss: 32.6999, Accuracy: 0.1822\n",
      "Epoch 39/50, Train Loss: 38.6282, Test Loss: 32.6942, Accuracy: 0.1822\n",
      "Epoch 40/50, Train Loss: 38.9754, Test Loss: 32.6885, Accuracy: 0.1822\n",
      "Epoch 41/50, Train Loss: 34.8006, Test Loss: 32.6828, Accuracy: 0.1822\n",
      "Epoch 42/50, Train Loss: 38.2401, Test Loss: 32.6772, Accuracy: 0.1822\n",
      "Epoch 43/50, Train Loss: 40.6508, Test Loss: 32.6715, Accuracy: 0.1822\n",
      "Epoch 44/50, Train Loss: 37.1053, Test Loss: 32.6657, Accuracy: 0.1822\n",
      "Epoch 45/50, Train Loss: 39.3042, Test Loss: 32.6600, Accuracy: 0.1822\n",
      "Epoch 46/50, Train Loss: 36.6795, Test Loss: 32.6543, Accuracy: 0.1822\n",
      "Epoch 47/50, Train Loss: 33.4211, Test Loss: 32.6486, Accuracy: 0.1822\n",
      "Epoch 48/50, Train Loss: 37.0979, Test Loss: 32.6429, Accuracy: 0.1822\n",
      "Epoch 49/50, Train Loss: 40.0451, Test Loss: 32.6372, Accuracy: 0.1822\n",
      "Epoch 50/50, Train Loss: 41.0399, Test Loss: 32.6314, Accuracy: 0.1822\n",
      "Running experiment with params: {'batch_size': 256, 'learning_rate': 0.0001, 'dropout_rate': 0.25}\n",
      "Epoch 1/50, Train Loss: 39.2551, Test Loss: 32.6310, Accuracy: 0.1822\n",
      "Epoch 2/50, Train Loss: 41.3129, Test Loss: 32.6305, Accuracy: 0.1822\n",
      "Epoch 3/50, Train Loss: 40.8153, Test Loss: 32.6300, Accuracy: 0.1822\n",
      "Epoch 4/50, Train Loss: 34.7998, Test Loss: 32.6295, Accuracy: 0.1822\n",
      "Epoch 5/50, Train Loss: 39.2000, Test Loss: 32.6291, Accuracy: 0.1822\n",
      "Epoch 6/50, Train Loss: 42.1476, Test Loss: 32.6286, Accuracy: 0.1822\n",
      "Epoch 7/50, Train Loss: 36.8488, Test Loss: 32.6281, Accuracy: 0.1822\n",
      "Epoch 8/50, Train Loss: 38.9751, Test Loss: 32.6276, Accuracy: 0.1822\n",
      "Epoch 9/50, Train Loss: 36.6466, Test Loss: 32.6271, Accuracy: 0.1822\n",
      "Epoch 10/50, Train Loss: 40.5238, Test Loss: 32.6266, Accuracy: 0.1822\n",
      "Epoch 11/50, Train Loss: 36.8428, Test Loss: 32.6261, Accuracy: 0.1822\n",
      "Epoch 12/50, Train Loss: 40.5306, Test Loss: 32.6256, Accuracy: 0.1822\n",
      "Epoch 13/50, Train Loss: 40.8099, Test Loss: 32.6251, Accuracy: 0.1822\n",
      "Epoch 14/50, Train Loss: 38.9080, Test Loss: 32.6246, Accuracy: 0.1822\n",
      "Epoch 15/50, Train Loss: 34.2779, Test Loss: 32.6241, Accuracy: 0.1822\n",
      "Epoch 16/50, Train Loss: 38.7466, Test Loss: 32.6236, Accuracy: 0.1822\n",
      "Epoch 17/50, Train Loss: 39.0420, Test Loss: 32.6231, Accuracy: 0.1822\n",
      "Epoch 18/50, Train Loss: 37.1430, Test Loss: 32.6226, Accuracy: 0.1822\n",
      "Epoch 19/50, Train Loss: 36.6265, Test Loss: 32.6221, Accuracy: 0.1822\n",
      "Epoch 20/50, Train Loss: 37.6225, Test Loss: 32.6216, Accuracy: 0.1822\n",
      "Epoch 21/50, Train Loss: 42.6447, Test Loss: 32.6211, Accuracy: 0.1822\n",
      "Epoch 22/50, Train Loss: 38.9760, Test Loss: 32.6206, Accuracy: 0.1822\n",
      "Epoch 23/50, Train Loss: 42.6393, Test Loss: 32.6201, Accuracy: 0.1822\n",
      "Epoch 24/50, Train Loss: 36.5520, Test Loss: 32.6196, Accuracy: 0.1822\n",
      "Epoch 25/50, Train Loss: 32.1179, Test Loss: 32.6191, Accuracy: 0.1822\n",
      "Epoch 26/50, Train Loss: 37.1197, Test Loss: 32.6186, Accuracy: 0.1822\n",
      "Epoch 27/50, Train Loss: 36.2863, Test Loss: 32.6180, Accuracy: 0.1822\n",
      "Epoch 28/50, Train Loss: 37.0706, Test Loss: 32.6175, Accuracy: 0.1822\n",
      "Epoch 29/50, Train Loss: 39.2364, Test Loss: 32.6170, Accuracy: 0.1822\n",
      "Epoch 30/50, Train Loss: 37.9018, Test Loss: 32.6165, Accuracy: 0.1822\n",
      "Epoch 31/50, Train Loss: 37.3374, Test Loss: 32.6160, Accuracy: 0.1822\n",
      "Epoch 32/50, Train Loss: 37.1163, Test Loss: 32.6154, Accuracy: 0.1822\n",
      "Epoch 33/50, Train Loss: 36.8521, Test Loss: 32.6149, Accuracy: 0.1822\n",
      "Epoch 34/50, Train Loss: 36.8469, Test Loss: 32.6144, Accuracy: 0.1822\n",
      "Epoch 35/50, Train Loss: 34.6610, Test Loss: 32.6139, Accuracy: 0.1822\n",
      "Epoch 36/50, Train Loss: 34.7323, Test Loss: 32.6133, Accuracy: 0.1822\n",
      "Epoch 37/50, Train Loss: 38.9684, Test Loss: 32.6128, Accuracy: 0.1822\n",
      "Epoch 38/50, Train Loss: 38.1804, Test Loss: 32.6123, Accuracy: 0.1822\n",
      "Epoch 39/50, Train Loss: 42.1334, Test Loss: 32.6117, Accuracy: 0.1822\n",
      "Epoch 40/50, Train Loss: 38.4602, Test Loss: 32.6112, Accuracy: 0.1822\n",
      "Epoch 41/50, Train Loss: 37.3122, Test Loss: 32.6107, Accuracy: 0.1822\n",
      "Epoch 42/50, Train Loss: 37.0486, Test Loss: 32.6101, Accuracy: 0.1822\n",
      "Epoch 43/50, Train Loss: 42.1261, Test Loss: 32.6096, Accuracy: 0.1822\n",
      "Epoch 44/50, Train Loss: 36.8465, Test Loss: 32.6090, Accuracy: 0.1822\n",
      "Epoch 45/50, Train Loss: 41.0672, Test Loss: 32.6085, Accuracy: 0.1822\n",
      "Epoch 46/50, Train Loss: 41.2777, Test Loss: 32.6080, Accuracy: 0.1822\n",
      "Epoch 47/50, Train Loss: 38.6571, Test Loss: 32.6074, Accuracy: 0.1822\n",
      "Epoch 48/50, Train Loss: 36.6250, Test Loss: 32.6069, Accuracy: 0.1822\n",
      "Epoch 49/50, Train Loss: 32.5066, Test Loss: 32.6063, Accuracy: 0.1822\n",
      "Epoch 50/50, Train Loss: 38.9562, Test Loss: 32.6058, Accuracy: 0.1822\n",
      "Running experiment with params: {'batch_size': 256, 'learning_rate': 0.0001, 'dropout_rate': 0.5}\n",
      "Epoch 1/50, Train Loss: 39.1716, Test Loss: 32.6053, Accuracy: 0.1822\n",
      "Epoch 2/50, Train Loss: 36.8387, Test Loss: 32.6048, Accuracy: 0.1822\n",
      "Epoch 3/50, Train Loss: 36.4010, Test Loss: 32.6043, Accuracy: 0.1822\n",
      "Epoch 4/50, Train Loss: 38.6531, Test Loss: 32.6039, Accuracy: 0.1822\n",
      "Epoch 5/50, Train Loss: 33.2728, Test Loss: 32.6034, Accuracy: 0.1822\n",
      "Epoch 6/50, Train Loss: 36.5544, Test Loss: 32.6029, Accuracy: 0.1822\n",
      "Epoch 7/50, Train Loss: 38.9528, Test Loss: 32.6025, Accuracy: 0.1822\n",
      "Epoch 8/50, Train Loss: 37.1221, Test Loss: 32.6020, Accuracy: 0.1822\n",
      "Epoch 9/50, Train Loss: 34.7214, Test Loss: 32.6015, Accuracy: 0.1822\n",
      "Epoch 10/50, Train Loss: 39.1524, Test Loss: 32.6010, Accuracy: 0.1822\n",
      "Epoch 11/50, Train Loss: 36.9047, Test Loss: 32.6005, Accuracy: 0.1822\n",
      "Epoch 12/50, Train Loss: 37.1863, Test Loss: 32.6000, Accuracy: 0.1822\n",
      "Epoch 13/50, Train Loss: 34.5505, Test Loss: 32.5995, Accuracy: 0.1822\n",
      "Epoch 14/50, Train Loss: 40.0019, Test Loss: 32.5990, Accuracy: 0.1822\n",
      "Epoch 15/50, Train Loss: 40.4982, Test Loss: 32.5985, Accuracy: 0.1822\n",
      "Epoch 16/50, Train Loss: 34.8504, Test Loss: 32.5981, Accuracy: 0.1822\n",
      "Epoch 17/50, Train Loss: 38.3851, Test Loss: 32.5976, Accuracy: 0.1822\n",
      "Epoch 18/50, Train Loss: 34.6978, Test Loss: 32.5971, Accuracy: 0.1822\n",
      "Epoch 19/50, Train Loss: 40.5020, Test Loss: 32.5966, Accuracy: 0.1822\n",
      "Epoch 20/50, Train Loss: 42.6076, Test Loss: 32.5961, Accuracy: 0.1822\n",
      "Epoch 21/50, Train Loss: 38.6383, Test Loss: 32.5956, Accuracy: 0.1822\n",
      "Epoch 22/50, Train Loss: 40.9973, Test Loss: 32.5951, Accuracy: 0.1822\n",
      "Epoch 23/50, Train Loss: 38.9159, Test Loss: 32.5946, Accuracy: 0.1822\n",
      "Epoch 24/50, Train Loss: 36.8325, Test Loss: 32.5941, Accuracy: 0.1822\n",
      "Epoch 25/50, Train Loss: 38.4470, Test Loss: 32.5936, Accuracy: 0.1822\n",
      "Epoch 26/50, Train Loss: 38.9493, Test Loss: 32.5931, Accuracy: 0.1822\n",
      "Epoch 27/50, Train Loss: 32.5955, Test Loss: 32.5926, Accuracy: 0.1822\n",
      "Epoch 28/50, Train Loss: 41.0661, Test Loss: 32.5920, Accuracy: 0.1822\n",
      "Epoch 29/50, Train Loss: 40.4908, Test Loss: 32.5915, Accuracy: 0.1822\n",
      "Epoch 30/50, Train Loss: 37.3121, Test Loss: 32.5910, Accuracy: 0.1822\n",
      "Epoch 31/50, Train Loss: 39.0061, Test Loss: 32.5905, Accuracy: 0.1822\n",
      "Epoch 32/50, Train Loss: 41.0577, Test Loss: 32.5900, Accuracy: 0.1822\n",
      "Epoch 33/50, Train Loss: 35.5397, Test Loss: 32.5894, Accuracy: 0.1822\n",
      "Epoch 34/50, Train Loss: 38.4422, Test Loss: 32.5889, Accuracy: 0.1822\n",
      "Epoch 35/50, Train Loss: 37.5844, Test Loss: 32.5884, Accuracy: 0.1822\n",
      "Epoch 36/50, Train Loss: 35.0348, Test Loss: 32.5879, Accuracy: 0.1822\n",
      "Epoch 37/50, Train Loss: 39.4344, Test Loss: 32.5873, Accuracy: 0.1822\n",
      "Epoch 38/50, Train Loss: 38.9431, Test Loss: 32.5868, Accuracy: 0.1822\n",
      "Epoch 39/50, Train Loss: 37.0932, Test Loss: 32.5863, Accuracy: 0.1822\n",
      "Epoch 40/50, Train Loss: 34.4700, Test Loss: 32.5857, Accuracy: 0.1822\n",
      "Epoch 41/50, Train Loss: 38.6393, Test Loss: 32.5852, Accuracy: 0.1822\n",
      "Epoch 42/50, Train Loss: 38.2007, Test Loss: 32.5847, Accuracy: 0.1822\n",
      "Epoch 43/50, Train Loss: 36.7512, Test Loss: 32.5841, Accuracy: 0.1822\n",
      "Epoch 44/50, Train Loss: 32.7884, Test Loss: 32.5836, Accuracy: 0.1822\n",
      "Epoch 45/50, Train Loss: 37.1464, Test Loss: 32.5831, Accuracy: 0.1822\n",
      "Epoch 46/50, Train Loss: 38.9905, Test Loss: 32.5825, Accuracy: 0.1822\n",
      "Epoch 47/50, Train Loss: 36.7926, Test Loss: 32.5820, Accuracy: 0.1822\n",
      "Epoch 48/50, Train Loss: 37.1012, Test Loss: 32.5815, Accuracy: 0.1822\n",
      "Epoch 49/50, Train Loss: 36.5174, Test Loss: 32.5809, Accuracy: 0.1822\n",
      "Epoch 50/50, Train Loss: 38.6422, Test Loss: 32.5804, Accuracy: 0.1822\n",
      "Best parameters: {'batch_size': 128, 'learning_rate': 0.1, 'dropout_rate': 0.5} with loss: 1.784406344095866\n"
     ]
    }
   ],
   "source": [
    "# Iteracja przez wszystkie kombinacje hiperparametrów\n",
    "best_params = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "for params in itertools.product(*param_space.values()):\n",
    "    param_dict = dict(zip(param_space.keys(), params))\n",
    "    print(f\"Running experiment with params: {param_dict}\")\n",
    "    loss = run_experiment(param_dict)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_params = param_dict\n",
    "\n",
    "print(f\"Best parameters: {best_params} with loss: {best_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c1b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
